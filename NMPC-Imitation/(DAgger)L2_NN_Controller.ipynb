{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himanshu069/trictrl/blob/sim/NMPC-Imitation/(DAgger)L2_NN_Controller.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETTEhTOPHwgI",
        "outputId": "e97e9c74-2906-42c8-861a-0204c785a9a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: do-mpc in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: casadi>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from do-mpc) (3.7.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from do-mpc) (1.16.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from do-mpc) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from do-mpc) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from do-mpc) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->do-mpc) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->do-mpc) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->do-mpc) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->do-mpc) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->do-mpc) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->do-mpc) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->do-mpc) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->do-mpc) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->do-mpc) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->do-mpc) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->do-mpc) (1.17.0)\n",
            "Requirement already satisfied: casadi in /usr/local/lib/python3.12/dist-packages (3.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from casadi) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"NN-controller with DAgger\"\"\"\n",
        "\n",
        "!pip install torch pandas matplotlib\n",
        "!pip install do-mpc\n",
        "!pip install casadi\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import do_mpc\n",
        "from casadi import *\n",
        "\n",
        "# -------------------- Data Loading --------------------\n",
        "df = pd.read_csv('nmpc_dataset[omega0andvarying].csv')\n",
        "df = df.sort_values(['time']).reset_index(drop=True)\n",
        "df['theta_next'] = df['theta'].shift(-1)\n",
        "df['dtheta_next'] = df['dtheta'].shift(-1)\n",
        "df['dphi_next'] = df['dphi'].shift(-1)\n",
        "df['dt'] = df['time'].diff().shift(-1)\n",
        "df = df.dropna()\n",
        "\n",
        "X = df[['theta', 'dtheta', 'dphi']].values.astype(np.float32)\n",
        "# X_next = df[['theta_next', 'dtheta_next', 'dphi_next']].values.astype(np.float32)\n",
        "dt_array = df['dt'].values.astype(np.float32)\n",
        "y = df['u'].values.reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "# indices = np.arange(len(X))\n",
        "# train_idx, temp_idx = train_test_split(indices, test_size=0.4, random_state=42)\n",
        "# val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
        "\n",
        "X_train, y_train = X, y\n",
        "# X_val, y_val = X[val_idx], y[val_idx]\n",
        "# X_test, y_test = X[test_idx], y[test_idx]\n",
        "\n",
        "# mean = X_train.mean(axis=0)\n",
        "# std = X_train.std(axis=0)\n",
        "# std[std == 0] = 1e-8\n",
        "\n",
        "# X_train = (X_train - mean) / std\n",
        "# X_val = (X_val - mean) / std\n",
        "# X_test = (X_test - mean) / std\n",
        "\n",
        "train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "# val_dataset = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "# test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "batch_size = 64\n",
        "initial_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bknp3ef5IcBb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -------------------- Neural Network --------------------\n",
        "class NMPCNet(nn.Module):\n",
        "    def __init__(self, input_dim=3, hidden1=64, hidden2=64, output_dim=1):\n",
        "        super(NMPCNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden1, hidden2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden2, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = NMPCNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCwWtuTxKNfe"
      },
      "outputs": [],
      "source": [
        "def dynamics_derivative(state, u):\n",
        "    \"\"\"\n",
        "    Computes the time derivative of the state\n",
        "    state: [theta, dtheta, dphi]\n",
        "    u: control torque\n",
        "    Returns: [dtheta, ddtheta, ddphi]\n",
        "    \"\"\"\n",
        "    theta, phi, dtheta, dphi = state\n",
        "\n",
        "    # Equations of motion\n",
        "    ddtheta = (M*g*np.sin(theta) - u) / I\n",
        "    ddphi = u/Iw - ddtheta\n",
        "\n",
        "    return np.array([dtheta, dphi, ddtheta, ddphi])\n",
        "\n",
        "def dynamics_step(state, u, dt):\n",
        "    \"\"\"\n",
        "    Simulates one step of the reaction wheel pendulum dynamics using RK4\n",
        "    state: [theta, dtheta, dphi]\n",
        "    u: control torque\n",
        "    dt: time step\n",
        "    Returns: next_state\n",
        "    \"\"\"\n",
        "    # RK4 integration\n",
        "    k1 = dynamics_derivative(state, u)\n",
        "    k2 = dynamics_derivative(state + dt/2 * k1, u)\n",
        "    k3 = dynamics_derivative(state + dt/2 * k2, u)\n",
        "    k4 = dynamics_derivative(state + dt * k3, u)\n",
        "\n",
        "    state_next = state + dt/6 * (k1 + 2*k2 + 2*k3 + k4)\n",
        "    state_next[0] = ((state_next[0] + np.pi) % (2*np.pi)) - np.pi\n",
        "\n",
        "    return state_next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsOfvT2nwBih"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# System parameters\n",
        "# ----------------------------\n",
        "M = 0.01825\n",
        "mb = 0.286\n",
        "mw = 0.079\n",
        "Iw = 0.000040394\n",
        "Ib = 0.0004370975\n",
        "lb = 0.05\n",
        "lw = 0.05\n",
        "g = 9.81\n",
        "I = Ib + mb*lb*lb + mw*lw*lw\n",
        "\n",
        "# ----------------------------\n",
        "# Model setup\n",
        "# ----------------------------\n",
        "model_type = 'continuous'\n",
        "model1 = do_mpc.model.Model(model_type)\n",
        "\n",
        "# States\n",
        "t_abs = model1.set_variable(var_type='_tvp', var_name='t_abs')\n",
        "theta = model1.set_variable('_x','theta')\n",
        "phi = model1.set_variable('_x','phi')\n",
        "dtheta = model1.set_variable('_x','dtheta')\n",
        "dphi = model1.set_variable('_x','dphi')\n",
        "\n",
        "# Control\n",
        "u = model1.set_variable('_u','torque')\n",
        "\n",
        "# Algebraic variables\n",
        "ddtheta = model1.set_variable('_z', 'ddtheta')\n",
        "ddphi = model1.set_variable('_z', 'ddphi')\n",
        "\n",
        "# RHS\n",
        "model1.set_rhs('theta', dtheta)\n",
        "model1.set_rhs('phi', dphi)\n",
        "model1.set_rhs('dtheta', ddtheta)\n",
        "model1.set_rhs('dphi', ddphi)\n",
        "\n",
        "# Euler-Lagrange equations\n",
        "euler_lagrange = vertcat(\n",
        "    (I+Iw)*ddtheta + Iw*ddphi - M*g*sin(theta),\n",
        "    Iw*(ddtheta + ddphi) - u\n",
        ")\n",
        "model1.set_alg('euler_lagrange', euler_lagrange)\n",
        "model1.setup()\n",
        "\n",
        "# ----------------------------\n",
        "# NMPC controller setup\n",
        "# ----------------------------\n",
        "mpc = do_mpc.controller.MPC(model1)\n",
        "setup_mpc = {\n",
        "    'n_horizon': 50,\n",
        "    'n_robust': 0,\n",
        "    'open_loop': 0,\n",
        "    't_step': 0.04,\n",
        "    'state_discretization': 'collocation',\n",
        "    'collocation_type': 'radau',\n",
        "    'collocation_deg': 6,\n",
        "    'collocation_ni': 1,\n",
        "    'store_full_solution': True,\n",
        "    'nlpsol_opts': {\n",
        "        'ipopt.linear_solver': 'mumps',\n",
        "        'ipopt.print_level': 0,\n",
        "        'print_time': 0,\n",
        "        'ipopt.sb': 'yes',\n",
        "        'verbose': False\n",
        "    }\n",
        "}\n",
        "mpc.set_param(**setup_mpc)\n",
        "\n",
        "# Objective\n",
        "Q1 = 1000\n",
        "Q2 = 5\n",
        "Q3 = 0.1\n",
        "R = 1.0\n",
        "omega_s = 0\n",
        "omega_ref = 0 + 4.95 * sin(0.5 * model1.tvp['t_abs'])\n",
        "mterm = Q1*model1.x['theta']**2 + Q2*model1.x['dtheta']**2 + Q3*(model1.x['dphi']-omega_s)**2\n",
        "lterm = Q1*model1.x['theta']**2 + Q2*model1.x['dtheta']**2 + Q3*(model1.x['dphi']-omega_ref)**2\n",
        "mpc.set_objective(mterm=mterm, lterm=lterm)\n",
        "mpc.set_rterm(torque=R)\n",
        "\n",
        "# Control bounds\n",
        "mpc.bounds['lower','_u','torque'] = -0.5\n",
        "mpc.bounds['upper','_u','torque'] = 0.5\n",
        "\n",
        "tvp_template_mpc = mpc.get_tvp_template()\n",
        "t_step = 0.04\n",
        "def tvp_fun(t_now):\n",
        "        for k in range(50+1):\n",
        "                tvp_template_mpc['_tvp',k,'t_abs'] = t_now + k*t_step\n",
        "\n",
        "        return tvp_template_mpc\n",
        "\n",
        "mpc.set_tvp_fun(tvp_fun)\n",
        "\n",
        "mpc.setup()\n",
        "\n",
        "# ----------------------------\n",
        "# Estimator and simulator\n",
        "# ----------------------------\n",
        "estimator = do_mpc.estimator.StateFeedback(model1)\n",
        "simulator = do_mpc.simulator.Simulator(model1)\n",
        "sim_params = {'integration_tool': 'idas', 'abstol':1e-8, 'reltol':1e-8, 't_step':0.04}\n",
        "simulator.set_param(**sim_params)\n",
        "tvp_template_sim = simulator.get_tvp_template()\n",
        "def tvp_fun_sim(t_now):\n",
        "        tvp_template_sim['t_abs'] = t_now\n",
        "        return tvp_template_sim\n",
        "simulator.set_tvp_fun(tvp_fun_sim)\n",
        "simulator.setup()\n",
        "\n",
        "def expert_policy(state, t_now = 0.0):\n",
        "    \"\"\"\n",
        "    Returns the first optimal NMPC input for the given state\n",
        "    state: np.array or torch tensor of shape (4,)\n",
        "    \"\"\"\n",
        "    if isinstance(state, torch.Tensor):\n",
        "        state = state.detach().cpu().numpy().flatten()\n",
        "\n",
        "    # Set initial state\n",
        "    mpc.t0 = t_now\n",
        "    mpc.x0 = state.reshape(-1,1)\n",
        "    mpc.reset_history()\n",
        "    mpc.set_initial_guess()\n",
        "    simulator.x0 = state.reshape(-1,1)\n",
        "    estimator.x0 = state.reshape(-1,1)\n",
        "\n",
        "    # Solve NMPC and return first control input\n",
        "    u_opt = mpc.make_step(state.reshape(-1,1))\n",
        "    return float(u_opt[0,0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_xXkytIIhO5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -------------------- Training --------------------\n",
        "def train_model(model, train_loader, val_loader, max_epochs=1000, patience=40, min_delta=1e-6):\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            # print(f\"Target u stats: mean={y_train.mean()}, std={y_train.std()}\")\n",
        "            # print(f\"Target u range: [{y_train.min()}, {y_train.max()}]\")\n",
        "            # print(f\"X_batch\", X_batch)\n",
        "            # print(f\"y_batch\", y_batch)\n",
        "            optimizer.zero_grad()\n",
        "            u_pred = model(X_batch)\n",
        "            loss = criterion(u_pred, y_batch)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * X_batch.size(0)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                u_pred = model(X_batch)\n",
        "                loss = criterion(u_pred, y_batch)\n",
        "                val_loss += loss.item() * X_batch.size(0)\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f'Epoch [{epoch+1}], Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}')\n",
        "\n",
        "        if best_val_loss - val_loss > min_delta:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_loss': val_loss,\n",
        "                'train_loss': train_loss\n",
        "            }\n",
        "            torch.save(checkpoint, 'best_model_checkpoint.pth')\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f'Early stopping after {epoch+1} epochs.')\n",
        "            break\n",
        "\n",
        "    return train_losses, val_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMmrk3JAIig7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
        "def rollout_policy(model, mean, std,env_dynamics, dt, rollout_steps=50, n_rollouts=20):\n",
        "    \"\"\"\n",
        "    Runs the current NN policy for multiple rollouts from random initial theta values.\n",
        "    Other states (dtheta, dphi) are initialized to zero.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_states = []\n",
        "    all_timesteps=[]\n",
        "\n",
        "    # Randomize theta only\n",
        "    for _ in range(n_rollouts):\n",
        "        theta0 = np.random.uniform(-np.pi, np.pi)\n",
        "        thetadot0 = np.random.uniform(-10.0,10.0)\n",
        "        state = np.array([theta0, 0.0, thetadot0, 0.0])\n",
        "        t_current = 0.0\n",
        "\n",
        "        for _ in range(rollout_steps):\n",
        "            s_nn = np.array([state[0], state[2], state[3]])\n",
        "            s_normalized = (s_nn - mean) / std\n",
        "            s_tensor = torch.tensor(s_normalized, dtype=torch.float32).unsqueeze(0)\n",
        "            with torch.no_grad():\n",
        "                u = model(s_tensor).squeeze().item()\n",
        "            next_state = dynamics_step(state, u, dt)\n",
        "            all_states.append(next_state)\n",
        "            all_timesteps.append(t_current)\n",
        "            state = next_state\n",
        "            t_current += dt\n",
        "\n",
        "    return (torch.tensor(np.array(all_states), dtype=torch.float32),torch.tensor(np.array(all_timesteps), dtype=torch.float32))\n",
        "\n",
        "all_train_losses, all_val_losses = [], []\n",
        "dagger_iteration_metrics = []\n",
        "def dagger_training(model, initial_loader, iterations=10, rollout_steps=50, dt=0.04):\n",
        "    \"\"\"\n",
        "    Online DAgger: iteratively train policy, roll out, query expert, and aggregate dataset.\n",
        "    \"\"\"\n",
        "    dataset_X, dataset_y = [], []\n",
        "\n",
        "    # Initialize dataset with expert demonstrations\n",
        "    for X_batch, y_batch in initial_loader:\n",
        "        dataset_X.append(X_batch)\n",
        "        dataset_y.append(y_batch)\n",
        "    dataset_X = torch.cat(dataset_X)\n",
        "    dataset_y = torch.cat(dataset_y)\n",
        "\n",
        "    global mean, std\n",
        "    X_np = dataset_X.numpy()\n",
        "    mean = X_np.mean(axis=0)\n",
        "    std = X_np.std(axis=0)\n",
        "    std[std == 0] = 1e-8\n",
        "\n",
        "    # Normalize initial dataset\n",
        "    X_normalized = (X_np - mean) / std\n",
        "    dataset_X = torch.from_numpy(X_normalized.astype(np.float32))\n",
        "    for i in range(iterations):\n",
        "        print(f\"\\n=== DAgger Iteration {i+1} ===\")\n",
        "\n",
        "        dataset = TensorDataset(dataset_X, dataset_y)\n",
        "        val_size = int(0.2 * len(dataset))\n",
        "        train_size = len(dataset) - val_size\n",
        "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "        dagger_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "        # Train current model on aggregated dataset\n",
        "        train_losses, val_losses = train_model(model, dagger_loader, val_loader)\n",
        "        all_train_losses.extend(train_losses)\n",
        "        all_val_losses.extend(val_losses)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = []\n",
        "            y_true = []\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                y_hat = model(X_batch)\n",
        "                y_pred.append(y_hat)\n",
        "                y_true.append(y_batch)\n",
        "            y_pred = torch.cat(y_pred).numpy()\n",
        "            y_true = torch.cat(y_true).numpy()\n",
        "\n",
        "        mse = np.mean((y_true - y_pred)**2)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = np.mean(np.abs(y_true - y_pred))\n",
        "        r2 = 1 - ((y_true - y_pred)**2).sum() / ((y_true - y_true.mean())**2).sum()\n",
        "        corr = np.corrcoef(y_true.flatten(), y_pred.flatten())[0,1]\n",
        "\n",
        "        # Save metrics for this iteration\n",
        "        dagger_iteration_metrics.append({\n",
        "            'iteration': i+1,\n",
        "            'MSE': mse,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2,\n",
        "            'Correlation': corr\n",
        "        })\n",
        "\n",
        "        print(f\"Iteration {i+1} Metrics: MSE={mse:.6f}, RMSE={rmse:.6f}, MAE={mae:.6f}, R2={r2:.6f}, Corr={corr:.6f}\")\n",
        "\n",
        "        state_limits = [(-np.pi, np.pi), (-0.05, 0.05), (-50.0, 50.0), (-2000.0, 2000.0)]\n",
        "        # Roll out current NN policy to gather new states\n",
        "        new_states, new_times = rollout_policy(model, mean, std, dynamics_step, dt, rollout_steps=rollout_steps, n_rollouts=10)\n",
        "\n",
        "        feasible_indices = []\n",
        "        for rollout_start in range(0, len(new_states), rollout_steps):\n",
        "          rollout_end = rollout_start + rollout_steps\n",
        "          rollout_states = new_states[rollout_start:rollout_end]\n",
        "          rollout_times = new_times[rollout_start:rollout_end]\n",
        "\n",
        "          feasible_rollout = True\n",
        "          for idx, s in enumerate(rollout_states):\n",
        "            feasible_rollout = True\n",
        "            s_full = np.array([s[0].item(), 0.0, s[1].item(), s[2].item()])\n",
        "            for j, (low, high) in enumerate(state_limits):\n",
        "              if s_full[j] < low or s_full[j] > high:\n",
        "                  feasible_rollout = False\n",
        "                  print(\"s_full\", s_full)\n",
        "                  break\n",
        "            if not feasible_rollout:\n",
        "                break\n",
        "          if feasible_rollout:\n",
        "              feasible_indices.extend(range(rollout_start, rollout_end))\n",
        "        new_states = new_states[feasible_indices]\n",
        "        new_times = new_times[feasible_indices]\n",
        "        print(\"feasible states\", len(new_states))\n",
        "\n",
        "        new_states_np = new_states.numpy()\n",
        "        new_states_np = np.clip(new_states_np, -1e3, 1e3)\n",
        "        new_states_nn = new_states_np[:, [0,2,3]]\n",
        "        new_states_normalized = (new_states_nn - mean) / std\n",
        "        new_states = torch.from_numpy(new_states_normalized.astype(np.float32))\n",
        "        # Query expert on visited states\n",
        "        expert_labels = []\n",
        "        for s, t in zip(new_states,new_times):\n",
        "            s_full = np.array([s[0].item(), 0.0, s[1].item(), s[2].item()])\n",
        "            t_val = t.item()\n",
        "            u_expert = expert_policy(s_full, t_now=t_val)\n",
        "            # print(f\"s_full: {s_full}, t_val: {t_val}, u_expert: {u_expert}\")\n",
        "            expert_labels.append([u_expert])\n",
        "        expert_labels = torch.tensor(expert_labels, dtype=torch.float32)\n",
        "\n",
        "        # Aggregate data\n",
        "        dataset_X = torch.cat([dataset_X, new_states])\n",
        "        dataset_y = torch.cat([dataset_y, expert_labels])\n",
        "\n",
        "        # X_np = dataset_X.numpy()\n",
        "        # mean = X_np.mean(axis=0)\n",
        "        # std = X_np.std(axis=0)\n",
        "        # std[std == 0] = 1e-8\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S8U5ylINIj0_",
        "outputId": "0d0727a2-4c03-466a-92ee-f17ecd536f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DAgger Iteration 1 ===\n",
            "Epoch [1], Train Loss: 0.005158, Val Loss: 0.001738\n",
            "Epoch [2], Train Loss: 0.001368, Val Loss: 0.001305\n",
            "Epoch [3], Train Loss: 0.001120, Val Loss: 0.001158\n",
            "Epoch [4], Train Loss: 0.000985, Val Loss: 0.001007\n",
            "Epoch [5], Train Loss: 0.000856, Val Loss: 0.000903\n",
            "Epoch [6], Train Loss: 0.000766, Val Loss: 0.000797\n",
            "Epoch [7], Train Loss: 0.000673, Val Loss: 0.000705\n",
            "Epoch [8], Train Loss: 0.000590, Val Loss: 0.000636\n",
            "Epoch [9], Train Loss: 0.000535, Val Loss: 0.000564\n",
            "Epoch [10], Train Loss: 0.000477, Val Loss: 0.000493\n",
            "Epoch [11], Train Loss: 0.000420, Val Loss: 0.000447\n",
            "Epoch [12], Train Loss: 0.000365, Val Loss: 0.000373\n",
            "Epoch [13], Train Loss: 0.000327, Val Loss: 0.000323\n",
            "Epoch [14], Train Loss: 0.000278, Val Loss: 0.000277\n",
            "Epoch [15], Train Loss: 0.000239, Val Loss: 0.000249\n",
            "Epoch [16], Train Loss: 0.000209, Val Loss: 0.000216\n",
            "Epoch [17], Train Loss: 0.000178, Val Loss: 0.000179\n",
            "Epoch [18], Train Loss: 0.000148, Val Loss: 0.000152\n",
            "Epoch [19], Train Loss: 0.000128, Val Loss: 0.000120\n",
            "Epoch [20], Train Loss: 0.000106, Val Loss: 0.000096\n",
            "Epoch [21], Train Loss: 0.000084, Val Loss: 0.000078\n",
            "Epoch [22], Train Loss: 0.000071, Val Loss: 0.000066\n",
            "Epoch [23], Train Loss: 0.000057, Val Loss: 0.000056\n",
            "Epoch [24], Train Loss: 0.000047, Val Loss: 0.000042\n",
            "Epoch [25], Train Loss: 0.000039, Val Loss: 0.000036\n",
            "Epoch [26], Train Loss: 0.000032, Val Loss: 0.000030\n",
            "Epoch [27], Train Loss: 0.000028, Val Loss: 0.000025\n",
            "Epoch [28], Train Loss: 0.000024, Val Loss: 0.000022\n",
            "Epoch [29], Train Loss: 0.000020, Val Loss: 0.000020\n",
            "Epoch [30], Train Loss: 0.000018, Val Loss: 0.000017\n",
            "Epoch [31], Train Loss: 0.000017, Val Loss: 0.000019\n",
            "Epoch [32], Train Loss: 0.000016, Val Loss: 0.000017\n",
            "Epoch [33], Train Loss: 0.000014, Val Loss: 0.000014\n",
            "Epoch [34], Train Loss: 0.000013, Val Loss: 0.000014\n",
            "Epoch [35], Train Loss: 0.000014, Val Loss: 0.000024\n",
            "Epoch [36], Train Loss: 0.000013, Val Loss: 0.000017\n",
            "Epoch [37], Train Loss: 0.000014, Val Loss: 0.000017\n",
            "Epoch [38], Train Loss: 0.000013, Val Loss: 0.000018\n",
            "Epoch [39], Train Loss: 0.000012, Val Loss: 0.000013\n",
            "Epoch [40], Train Loss: 0.000011, Val Loss: 0.000014\n",
            "Epoch [41], Train Loss: 0.000010, Val Loss: 0.000013\n",
            "Epoch [42], Train Loss: 0.000012, Val Loss: 0.000018\n",
            "Epoch [43], Train Loss: 0.000011, Val Loss: 0.000018\n",
            "Epoch [44], Train Loss: 0.000011, Val Loss: 0.000017\n",
            "Epoch [45], Train Loss: 0.000011, Val Loss: 0.000012\n",
            "Epoch [46], Train Loss: 0.000010, Val Loss: 0.000012\n",
            "Epoch [47], Train Loss: 0.000017, Val Loss: 0.000012\n",
            "Epoch [48], Train Loss: 0.000010, Val Loss: 0.000013\n",
            "Epoch [49], Train Loss: 0.000010, Val Loss: 0.000010\n",
            "Epoch [50], Train Loss: 0.000011, Val Loss: 0.000019\n",
            "Epoch [51], Train Loss: 0.000014, Val Loss: 0.000017\n",
            "Epoch [52], Train Loss: 0.000012, Val Loss: 0.000009\n",
            "Epoch [53], Train Loss: 0.000013, Val Loss: 0.000013\n",
            "Epoch [54], Train Loss: 0.000010, Val Loss: 0.000016\n",
            "Epoch [55], Train Loss: 0.000011, Val Loss: 0.000011\n",
            "Epoch [56], Train Loss: 0.000009, Val Loss: 0.000012\n",
            "Epoch [57], Train Loss: 0.000009, Val Loss: 0.000014\n",
            "Epoch [58], Train Loss: 0.000020, Val Loss: 0.000015\n",
            "Epoch [59], Train Loss: 0.000010, Val Loss: 0.000017\n",
            "Epoch [60], Train Loss: 0.000008, Val Loss: 0.000008\n",
            "Epoch [61], Train Loss: 0.000008, Val Loss: 0.000010\n",
            "Epoch [62], Train Loss: 0.000009, Val Loss: 0.000008\n",
            "Epoch [63], Train Loss: 0.000008, Val Loss: 0.000009\n",
            "Epoch [64], Train Loss: 0.000007, Val Loss: 0.000008\n",
            "Epoch [65], Train Loss: 0.000011, Val Loss: 0.000016\n",
            "Epoch [66], Train Loss: 0.000010, Val Loss: 0.000014\n",
            "Epoch [67], Train Loss: 0.000009, Val Loss: 0.000014\n",
            "Epoch [68], Train Loss: 0.000008, Val Loss: 0.000007\n",
            "Epoch [69], Train Loss: 0.000009, Val Loss: 0.000012\n",
            "Epoch [70], Train Loss: 0.000010, Val Loss: 0.000010\n",
            "Epoch [71], Train Loss: 0.000007, Val Loss: 0.000009\n",
            "Epoch [72], Train Loss: 0.000010, Val Loss: 0.000027\n",
            "Epoch [73], Train Loss: 0.000008, Val Loss: 0.000007\n",
            "Epoch [74], Train Loss: 0.000007, Val Loss: 0.000008\n",
            "Epoch [75], Train Loss: 0.000006, Val Loss: 0.000007\n",
            "Epoch [76], Train Loss: 0.000007, Val Loss: 0.000009\n",
            "Epoch [77], Train Loss: 0.000008, Val Loss: 0.000006\n",
            "Epoch [78], Train Loss: 0.000006, Val Loss: 0.000008\n",
            "Epoch [79], Train Loss: 0.000006, Val Loss: 0.000012\n",
            "Epoch [80], Train Loss: 0.000006, Val Loss: 0.000008\n",
            "Epoch [81], Train Loss: 0.000007, Val Loss: 0.000010\n",
            "Epoch [82], Train Loss: 0.000007, Val Loss: 0.000010\n",
            "Epoch [83], Train Loss: 0.000006, Val Loss: 0.000013\n",
            "Epoch [84], Train Loss: 0.000007, Val Loss: 0.000006\n",
            "Epoch [85], Train Loss: 0.000008, Val Loss: 0.000007\n",
            "Epoch [86], Train Loss: 0.000007, Val Loss: 0.000016\n",
            "Epoch [87], Train Loss: 0.000014, Val Loss: 0.000011\n",
            "Epoch [88], Train Loss: 0.000012, Val Loss: 0.000005\n",
            "Epoch [89], Train Loss: 0.000005, Val Loss: 0.000008\n",
            "Epoch [90], Train Loss: 0.000005, Val Loss: 0.000005\n",
            "Epoch [91], Train Loss: 0.000005, Val Loss: 0.000007\n",
            "Epoch [92], Train Loss: 0.000005, Val Loss: 0.000006\n",
            "Epoch [93], Train Loss: 0.000007, Val Loss: 0.000008\n",
            "Epoch [94], Train Loss: 0.000006, Val Loss: 0.000006\n",
            "Epoch [95], Train Loss: 0.000006, Val Loss: 0.000008\n",
            "Epoch [96], Train Loss: 0.000006, Val Loss: 0.000005\n",
            "Epoch [97], Train Loss: 0.000008, Val Loss: 0.000008\n",
            "Epoch [98], Train Loss: 0.000005, Val Loss: 0.000007\n",
            "Epoch [99], Train Loss: 0.000011, Val Loss: 0.000011\n",
            "Epoch [100], Train Loss: 0.000004, Val Loss: 0.000005\n",
            "Epoch [101], Train Loss: 0.000008, Val Loss: 0.000006\n",
            "Epoch [102], Train Loss: 0.000005, Val Loss: 0.000004\n",
            "Epoch [103], Train Loss: 0.000006, Val Loss: 0.000016\n",
            "Epoch [104], Train Loss: 0.000007, Val Loss: 0.000008\n",
            "Epoch [105], Train Loss: 0.000005, Val Loss: 0.000013\n",
            "Epoch [106], Train Loss: 0.000021, Val Loss: 0.000007\n",
            "Epoch [107], Train Loss: 0.000004, Val Loss: 0.000004\n",
            "Epoch [108], Train Loss: 0.000003, Val Loss: 0.000004\n",
            "Epoch [109], Train Loss: 0.000004, Val Loss: 0.000005\n",
            "Epoch [110], Train Loss: 0.000003, Val Loss: 0.000004\n",
            "Epoch [111], Train Loss: 0.000004, Val Loss: 0.000004\n",
            "Epoch [112], Train Loss: 0.000008, Val Loss: 0.000007\n",
            "Epoch [113], Train Loss: 0.000005, Val Loss: 0.000004\n",
            "Epoch [114], Train Loss: 0.000006, Val Loss: 0.000005\n",
            "Epoch [115], Train Loss: 0.000005, Val Loss: 0.000005\n",
            "Epoch [116], Train Loss: 0.000006, Val Loss: 0.000004\n",
            "Epoch [117], Train Loss: 0.000007, Val Loss: 0.000003\n",
            "Epoch [118], Train Loss: 0.000004, Val Loss: 0.000008\n",
            "Epoch [119], Train Loss: 0.000012, Val Loss: 0.000006\n",
            "Epoch [120], Train Loss: 0.000005, Val Loss: 0.000004\n",
            "Epoch [121], Train Loss: 0.000004, Val Loss: 0.000004\n",
            "Epoch [122], Train Loss: 0.000004, Val Loss: 0.000013\n",
            "Epoch [123], Train Loss: 0.000003, Val Loss: 0.000006\n",
            "Epoch [124], Train Loss: 0.000004, Val Loss: 0.000004\n",
            "Epoch [125], Train Loss: 0.000008, Val Loss: 0.000018\n",
            "Epoch [126], Train Loss: 0.000006, Val Loss: 0.000004\n",
            "Epoch [127], Train Loss: 0.000003, Val Loss: 0.000003\n",
            "Epoch [128], Train Loss: 0.000004, Val Loss: 0.000003\n",
            "Epoch [129], Train Loss: 0.000005, Val Loss: 0.000004\n",
            "Epoch [130], Train Loss: 0.000005, Val Loss: 0.000008\n",
            "Epoch [131], Train Loss: 0.000004, Val Loss: 0.000004\n",
            "Epoch [132], Train Loss: 0.000006, Val Loss: 0.000019\n",
            "Epoch [133], Train Loss: 0.000024, Val Loss: 0.000010\n",
            "Epoch [134], Train Loss: 0.000005, Val Loss: 0.000004\n",
            "Epoch [135], Train Loss: 0.000004, Val Loss: 0.000003\n",
            "Epoch [136], Train Loss: 0.000003, Val Loss: 0.000004\n",
            "Epoch [137], Train Loss: 0.000003, Val Loss: 0.000003\n",
            "Epoch [138], Train Loss: 0.000002, Val Loss: 0.000003\n",
            "Epoch [139], Train Loss: 0.000003, Val Loss: 0.000003\n",
            "Epoch [140], Train Loss: 0.000003, Val Loss: 0.000003\n",
            "Epoch [141], Train Loss: 0.000003, Val Loss: 0.000003\n",
            "Epoch [142], Train Loss: 0.000005, Val Loss: 0.000003\n",
            "Epoch [143], Train Loss: 0.000002, Val Loss: 0.000003\n",
            "Epoch [144], Train Loss: 0.000003, Val Loss: 0.000003\n",
            "Epoch [145], Train Loss: 0.000014, Val Loss: 0.000008\n",
            "Epoch [146], Train Loss: 0.000004, Val Loss: 0.000004\n",
            "Epoch [147], Train Loss: 0.000003, Val Loss: 0.000003\n",
            "Epoch [148], Train Loss: 0.000003, Val Loss: 0.000006\n",
            "Epoch [149], Train Loss: 0.000008, Val Loss: 0.000004\n",
            "Epoch [150], Train Loss: 0.000003, Val Loss: 0.000003\n",
            "Epoch [151], Train Loss: 0.000004, Val Loss: 0.000004\n",
            "Epoch [152], Train Loss: 0.000007, Val Loss: 0.000006\n",
            "Epoch [153], Train Loss: 0.000008, Val Loss: 0.000012\n",
            "Epoch [154], Train Loss: 0.000004, Val Loss: 0.000003\n",
            "Epoch [155], Train Loss: 0.000003, Val Loss: 0.000002\n",
            "Epoch [156], Train Loss: 0.000003, Val Loss: 0.000006\n",
            "Epoch [157], Train Loss: 0.000006, Val Loss: 0.000005\n",
            "Epoch [158], Train Loss: 0.000007, Val Loss: 0.000003\n",
            "Epoch [159], Train Loss: 0.000003, Val Loss: 0.000003\n",
            "Epoch [160], Train Loss: 0.000004, Val Loss: 0.000012\n",
            "Epoch [161], Train Loss: 0.000004, Val Loss: 0.000003\n",
            "Epoch [162], Train Loss: 0.000002, Val Loss: 0.000003\n",
            "Epoch [163], Train Loss: 0.000003, Val Loss: 0.000003\n",
            "Epoch [164], Train Loss: 0.000004, Val Loss: 0.000004\n",
            "Epoch [165], Train Loss: 0.000023, Val Loss: 0.000006\n",
            "Epoch [166], Train Loss: 0.000003, Val Loss: 0.000002\n",
            "Epoch [167], Train Loss: 0.000002, Val Loss: 0.000003\n",
            "Early stopping after 167 epochs.\n",
            "Iteration 1 Metrics: MSE=0.000003, RMSE=0.001685, MAE=0.000810, R2=0.999778, Corr=0.999889\n",
            "s_full [  0.93288457   0.          76.87114716 -34.67692566]\n",
            "s_full [ -0.87949741   0.         -89.67891693  28.24460793]\n",
            "s_full [ -0.30463254   0.         -67.01721954  14.48027039]\n",
            "s_full [ 1.10596707e-02  0.00000000e+00  5.28979034e+01 -4.66291189e+00]\n",
            "s_full [ -0.39788324   0.         -90.01299286  23.08216858]\n",
            "s_full [  0.75643742   0.          73.96243286 -24.19922066]\n",
            "feasible states 200\n",
            "\n",
            "=== DAgger Iteration 2 ===\n",
            "Epoch [1], Train Loss: 0.000135, Val Loss: 0.000183\n",
            "Epoch [2], Train Loss: 0.000136, Val Loss: 0.000363\n",
            "Epoch [3], Train Loss: 0.000145, Val Loss: 0.000177\n",
            "Epoch [4], Train Loss: 0.000113, Val Loss: 0.000184\n",
            "Epoch [5], Train Loss: 0.000115, Val Loss: 0.000171\n",
            "Epoch [6], Train Loss: 0.000108, Val Loss: 0.000178\n",
            "Epoch [7], Train Loss: 0.000106, Val Loss: 0.000193\n",
            "Epoch [8], Train Loss: 0.000108, Val Loss: 0.000174\n",
            "Epoch [9], Train Loss: 0.000110, Val Loss: 0.000178\n",
            "Epoch [10], Train Loss: 0.000104, Val Loss: 0.000188\n",
            "Epoch [11], Train Loss: 0.000110, Val Loss: 0.000174\n",
            "Epoch [12], Train Loss: 0.000108, Val Loss: 0.000173\n",
            "Epoch [13], Train Loss: 0.000106, Val Loss: 0.000173\n",
            "Epoch [14], Train Loss: 0.000102, Val Loss: 0.000214\n",
            "Epoch [15], Train Loss: 0.000102, Val Loss: 0.000171\n",
            "Epoch [16], Train Loss: 0.000100, Val Loss: 0.000179\n",
            "Epoch [17], Train Loss: 0.000099, Val Loss: 0.000173\n",
            "Epoch [18], Train Loss: 0.000101, Val Loss: 0.000172\n",
            "Epoch [19], Train Loss: 0.000101, Val Loss: 0.000173\n",
            "Epoch [20], Train Loss: 0.000104, Val Loss: 0.000173\n",
            "Epoch [21], Train Loss: 0.000098, Val Loss: 0.000175\n",
            "Epoch [22], Train Loss: 0.000100, Val Loss: 0.000172\n",
            "Epoch [23], Train Loss: 0.000097, Val Loss: 0.000173\n",
            "Epoch [24], Train Loss: 0.000101, Val Loss: 0.000174\n",
            "Epoch [25], Train Loss: 0.000098, Val Loss: 0.000180\n",
            "Epoch [26], Train Loss: 0.000101, Val Loss: 0.000175\n",
            "Epoch [27], Train Loss: 0.000097, Val Loss: 0.000178\n",
            "Epoch [28], Train Loss: 0.000103, Val Loss: 0.000176\n",
            "Epoch [29], Train Loss: 0.000097, Val Loss: 0.000178\n",
            "Epoch [30], Train Loss: 0.000099, Val Loss: 0.000179\n",
            "Epoch [31], Train Loss: 0.000102, Val Loss: 0.000204\n",
            "Epoch [32], Train Loss: 0.000105, Val Loss: 0.000173\n",
            "Epoch [33], Train Loss: 0.000096, Val Loss: 0.000178\n",
            "Epoch [34], Train Loss: 0.000097, Val Loss: 0.000174\n",
            "Epoch [35], Train Loss: 0.000097, Val Loss: 0.000181\n",
            "Epoch [36], Train Loss: 0.000098, Val Loss: 0.000176\n",
            "Epoch [37], Train Loss: 0.000096, Val Loss: 0.000180\n",
            "Epoch [38], Train Loss: 0.000096, Val Loss: 0.000176\n",
            "Epoch [39], Train Loss: 0.000093, Val Loss: 0.000178\n",
            "Epoch [40], Train Loss: 0.000096, Val Loss: 0.000177\n",
            "Epoch [41], Train Loss: 0.000093, Val Loss: 0.000181\n",
            "Epoch [42], Train Loss: 0.000094, Val Loss: 0.000190\n",
            "Epoch [43], Train Loss: 0.000095, Val Loss: 0.000179\n",
            "Epoch [44], Train Loss: 0.000096, Val Loss: 0.000175\n",
            "Epoch [45], Train Loss: 0.000091, Val Loss: 0.000220\n",
            "Early stopping after 45 epochs.\n",
            "Iteration 2 Metrics: MSE=0.000220, RMSE=0.014831, MAE=0.004242, R2=0.982670, Corr=0.991786\n",
            "s_full [-0.09156028  0.         51.15618134 -5.98442745]\n",
            "s_full [  0.21440695   0.          50.8309021  -12.53666115]\n",
            "s_full [  0.15125474   0.          50.61326218 -11.22579288]\n",
            "s_full [  0.09958285   0.         -51.72663116  -0.84921211]\n",
            "s_full [  0.73551339   0.          94.36276245 -28.56501007]\n",
            "s_full [ -0.46300641   0.         -96.37119293  25.01133919]\n",
            "s_full [  -1.03613162    0.         -101.98429871   31.92723465]\n",
            "s_full [  1.2309041    0.          59.06159592 -27.66448021]\n",
            "feasible states 100\n",
            "\n",
            "=== DAgger Iteration 3 ===\n",
            "Epoch [1], Train Loss: 0.000203, Val Loss: 0.000269\n",
            "Epoch [2], Train Loss: 0.000199, Val Loss: 0.000271\n",
            "Epoch [3], Train Loss: 0.000196, Val Loss: 0.000249\n",
            "Epoch [4], Train Loss: 0.000194, Val Loss: 0.000267\n",
            "Epoch [5], Train Loss: 0.000193, Val Loss: 0.000247\n",
            "Epoch [6], Train Loss: 0.000204, Val Loss: 0.000247\n",
            "Epoch [7], Train Loss: 0.000192, Val Loss: 0.000257\n",
            "Epoch [8], Train Loss: 0.000189, Val Loss: 0.000254\n",
            "Epoch [9], Train Loss: 0.000193, Val Loss: 0.000244\n",
            "Epoch [10], Train Loss: 0.000190, Val Loss: 0.000246\n",
            "Epoch [11], Train Loss: 0.000196, Val Loss: 0.000248\n",
            "Epoch [12], Train Loss: 0.000187, Val Loss: 0.000243\n",
            "Epoch [13], Train Loss: 0.000188, Val Loss: 0.000258\n",
            "Epoch [14], Train Loss: 0.000191, Val Loss: 0.000268\n",
            "Epoch [15], Train Loss: 0.000185, Val Loss: 0.000252\n",
            "Epoch [16], Train Loss: 0.000184, Val Loss: 0.000249\n",
            "Epoch [17], Train Loss: 0.000183, Val Loss: 0.000276\n",
            "Epoch [18], Train Loss: 0.000182, Val Loss: 0.000240\n",
            "Epoch [19], Train Loss: 0.000183, Val Loss: 0.000244\n",
            "Epoch [20], Train Loss: 0.000185, Val Loss: 0.000262\n",
            "Epoch [21], Train Loss: 0.000190, Val Loss: 0.000247\n",
            "Epoch [22], Train Loss: 0.000183, Val Loss: 0.000240\n",
            "Epoch [23], Train Loss: 0.000185, Val Loss: 0.000242\n",
            "Epoch [24], Train Loss: 0.000180, Val Loss: 0.000242\n",
            "Epoch [25], Train Loss: 0.000181, Val Loss: 0.000242\n",
            "Epoch [26], Train Loss: 0.000177, Val Loss: 0.000238\n",
            "Epoch [27], Train Loss: 0.000190, Val Loss: 0.000240\n",
            "Epoch [28], Train Loss: 0.000178, Val Loss: 0.000261\n",
            "Epoch [29], Train Loss: 0.000183, Val Loss: 0.000243\n",
            "Epoch [30], Train Loss: 0.000177, Val Loss: 0.000238\n",
            "Epoch [31], Train Loss: 0.000177, Val Loss: 0.000238\n",
            "Epoch [32], Train Loss: 0.000177, Val Loss: 0.000242\n",
            "Epoch [33], Train Loss: 0.000177, Val Loss: 0.000247\n",
            "Epoch [34], Train Loss: 0.000172, Val Loss: 0.000245\n",
            "Epoch [35], Train Loss: 0.000177, Val Loss: 0.000239\n",
            "Epoch [36], Train Loss: 0.000179, Val Loss: 0.000235\n",
            "Epoch [37], Train Loss: 0.000174, Val Loss: 0.000238\n",
            "Epoch [38], Train Loss: 0.000175, Val Loss: 0.000253\n",
            "Epoch [39], Train Loss: 0.000175, Val Loss: 0.000250\n",
            "Epoch [40], Train Loss: 0.000178, Val Loss: 0.000240\n",
            "Epoch [41], Train Loss: 0.000179, Val Loss: 0.000241\n",
            "Epoch [42], Train Loss: 0.000172, Val Loss: 0.000242\n",
            "Epoch [43], Train Loss: 0.000174, Val Loss: 0.000240\n",
            "Epoch [44], Train Loss: 0.000173, Val Loss: 0.000256\n",
            "Epoch [45], Train Loss: 0.000171, Val Loss: 0.000240\n",
            "Epoch [46], Train Loss: 0.000169, Val Loss: 0.000244\n",
            "Epoch [47], Train Loss: 0.000178, Val Loss: 0.000233\n",
            "Epoch [48], Train Loss: 0.000169, Val Loss: 0.000237\n",
            "Epoch [49], Train Loss: 0.000171, Val Loss: 0.000240\n",
            "Epoch [50], Train Loss: 0.000170, Val Loss: 0.000241\n",
            "Epoch [51], Train Loss: 0.000172, Val Loss: 0.000249\n",
            "Epoch [52], Train Loss: 0.000176, Val Loss: 0.000236\n",
            "Epoch [53], Train Loss: 0.000168, Val Loss: 0.000247\n",
            "Epoch [54], Train Loss: 0.000168, Val Loss: 0.000274\n",
            "Epoch [55], Train Loss: 0.000169, Val Loss: 0.000238\n",
            "Epoch [56], Train Loss: 0.000168, Val Loss: 0.000285\n",
            "Epoch [57], Train Loss: 0.000176, Val Loss: 0.000258\n",
            "Epoch [58], Train Loss: 0.000170, Val Loss: 0.000242\n",
            "Epoch [59], Train Loss: 0.000166, Val Loss: 0.000255\n",
            "Epoch [60], Train Loss: 0.000180, Val Loss: 0.000292\n",
            "Epoch [61], Train Loss: 0.000168, Val Loss: 0.000231\n",
            "Epoch [62], Train Loss: 0.000163, Val Loss: 0.000233\n",
            "Epoch [63], Train Loss: 0.000168, Val Loss: 0.000232\n",
            "Epoch [64], Train Loss: 0.000164, Val Loss: 0.000229\n",
            "Epoch [65], Train Loss: 0.000164, Val Loss: 0.000240\n",
            "Epoch [66], Train Loss: 0.000168, Val Loss: 0.000233\n",
            "Epoch [67], Train Loss: 0.000165, Val Loss: 0.000238\n",
            "Epoch [68], Train Loss: 0.000166, Val Loss: 0.000239\n",
            "Epoch [69], Train Loss: 0.000165, Val Loss: 0.000245\n",
            "Epoch [70], Train Loss: 0.000164, Val Loss: 0.000228\n",
            "Epoch [71], Train Loss: 0.000166, Val Loss: 0.000243\n",
            "Epoch [72], Train Loss: 0.000162, Val Loss: 0.000228\n",
            "Epoch [73], Train Loss: 0.000162, Val Loss: 0.000246\n",
            "Epoch [74], Train Loss: 0.000164, Val Loss: 0.000232\n",
            "Epoch [75], Train Loss: 0.000166, Val Loss: 0.000227\n",
            "Epoch [76], Train Loss: 0.000161, Val Loss: 0.000226\n",
            "Epoch [77], Train Loss: 0.000159, Val Loss: 0.000230\n",
            "Epoch [78], Train Loss: 0.000166, Val Loss: 0.000228\n",
            "Epoch [79], Train Loss: 0.000159, Val Loss: 0.000226\n",
            "Epoch [80], Train Loss: 0.000159, Val Loss: 0.000231\n",
            "Epoch [81], Train Loss: 0.000169, Val Loss: 0.000231\n",
            "Epoch [82], Train Loss: 0.000159, Val Loss: 0.000242\n",
            "Epoch [83], Train Loss: 0.000164, Val Loss: 0.000231\n",
            "Epoch [84], Train Loss: 0.000162, Val Loss: 0.000237\n",
            "Epoch [85], Train Loss: 0.000162, Val Loss: 0.000225\n",
            "Epoch [86], Train Loss: 0.000163, Val Loss: 0.000245\n",
            "Epoch [87], Train Loss: 0.000164, Val Loss: 0.000270\n",
            "Epoch [88], Train Loss: 0.000164, Val Loss: 0.000226\n",
            "Epoch [89], Train Loss: 0.000160, Val Loss: 0.000229\n",
            "Epoch [90], Train Loss: 0.000160, Val Loss: 0.000234\n",
            "Epoch [91], Train Loss: 0.000161, Val Loss: 0.000225\n",
            "Epoch [92], Train Loss: 0.000158, Val Loss: 0.000228\n",
            "Epoch [93], Train Loss: 0.000159, Val Loss: 0.000265\n",
            "Epoch [94], Train Loss: 0.000166, Val Loss: 0.000229\n",
            "Epoch [95], Train Loss: 0.000167, Val Loss: 0.000232\n",
            "Epoch [96], Train Loss: 0.000156, Val Loss: 0.000224\n",
            "Epoch [97], Train Loss: 0.000154, Val Loss: 0.000226\n",
            "Epoch [98], Train Loss: 0.000155, Val Loss: 0.000226\n",
            "Epoch [99], Train Loss: 0.000154, Val Loss: 0.000223\n",
            "Epoch [100], Train Loss: 0.000160, Val Loss: 0.000224\n",
            "Epoch [101], Train Loss: 0.000155, Val Loss: 0.000223\n",
            "Epoch [102], Train Loss: 0.000154, Val Loss: 0.000228\n",
            "Epoch [103], Train Loss: 0.000153, Val Loss: 0.000222\n",
            "Epoch [104], Train Loss: 0.000155, Val Loss: 0.000223\n",
            "Epoch [105], Train Loss: 0.000153, Val Loss: 0.000230\n",
            "Epoch [106], Train Loss: 0.000155, Val Loss: 0.000237\n",
            "Epoch [107], Train Loss: 0.000159, Val Loss: 0.000228\n",
            "Epoch [108], Train Loss: 0.000154, Val Loss: 0.000236\n",
            "Epoch [109], Train Loss: 0.000155, Val Loss: 0.000229\n",
            "Epoch [110], Train Loss: 0.000155, Val Loss: 0.000219\n",
            "Epoch [111], Train Loss: 0.000154, Val Loss: 0.000227\n",
            "Epoch [112], Train Loss: 0.000152, Val Loss: 0.000221\n",
            "Epoch [113], Train Loss: 0.000153, Val Loss: 0.000222\n",
            "Epoch [114], Train Loss: 0.000154, Val Loss: 0.000220\n",
            "Epoch [115], Train Loss: 0.000152, Val Loss: 0.000222\n",
            "Epoch [116], Train Loss: 0.000158, Val Loss: 0.000225\n",
            "Epoch [117], Train Loss: 0.000151, Val Loss: 0.000220\n",
            "Epoch [118], Train Loss: 0.000155, Val Loss: 0.000229\n",
            "Epoch [119], Train Loss: 0.000154, Val Loss: 0.000228\n",
            "Epoch [120], Train Loss: 0.000150, Val Loss: 0.000230\n",
            "Epoch [121], Train Loss: 0.000155, Val Loss: 0.000263\n",
            "Epoch [122], Train Loss: 0.000155, Val Loss: 0.000224\n",
            "Epoch [123], Train Loss: 0.000150, Val Loss: 0.000224\n",
            "Epoch [124], Train Loss: 0.000153, Val Loss: 0.000221\n",
            "Epoch [125], Train Loss: 0.000147, Val Loss: 0.000240\n",
            "Epoch [126], Train Loss: 0.000151, Val Loss: 0.000221\n",
            "Epoch [127], Train Loss: 0.000151, Val Loss: 0.000218\n",
            "Epoch [128], Train Loss: 0.000151, Val Loss: 0.000217\n",
            "Epoch [129], Train Loss: 0.000149, Val Loss: 0.000227\n",
            "Epoch [130], Train Loss: 0.000148, Val Loss: 0.000216\n",
            "Epoch [131], Train Loss: 0.000149, Val Loss: 0.000219\n",
            "Epoch [132], Train Loss: 0.000150, Val Loss: 0.000221\n",
            "Epoch [133], Train Loss: 0.000149, Val Loss: 0.000229\n",
            "Epoch [134], Train Loss: 0.000148, Val Loss: 0.000231\n",
            "Epoch [135], Train Loss: 0.000149, Val Loss: 0.000218\n",
            "Epoch [136], Train Loss: 0.000145, Val Loss: 0.000229\n",
            "Epoch [137], Train Loss: 0.000146, Val Loss: 0.000223\n",
            "Epoch [138], Train Loss: 0.000149, Val Loss: 0.000225\n",
            "Epoch [139], Train Loss: 0.000146, Val Loss: 0.000227\n",
            "Epoch [140], Train Loss: 0.000151, Val Loss: 0.000220\n",
            "Epoch [141], Train Loss: 0.000147, Val Loss: 0.000230\n",
            "Epoch [142], Train Loss: 0.000147, Val Loss: 0.000216\n",
            "Epoch [143], Train Loss: 0.000147, Val Loss: 0.000223\n",
            "Epoch [144], Train Loss: 0.000145, Val Loss: 0.000227\n",
            "Epoch [145], Train Loss: 0.000148, Val Loss: 0.000215\n",
            "Epoch [146], Train Loss: 0.000142, Val Loss: 0.000215\n",
            "Epoch [147], Train Loss: 0.000152, Val Loss: 0.000240\n",
            "Epoch [148], Train Loss: 0.000147, Val Loss: 0.000215\n",
            "Epoch [149], Train Loss: 0.000148, Val Loss: 0.000276\n",
            "Epoch [150], Train Loss: 0.000156, Val Loss: 0.000229\n",
            "Epoch [151], Train Loss: 0.000145, Val Loss: 0.000226\n",
            "Epoch [152], Train Loss: 0.000142, Val Loss: 0.000220\n",
            "Epoch [153], Train Loss: 0.000141, Val Loss: 0.000213\n",
            "Epoch [154], Train Loss: 0.000143, Val Loss: 0.000215\n",
            "Epoch [155], Train Loss: 0.000144, Val Loss: 0.000227\n",
            "Epoch [156], Train Loss: 0.000144, Val Loss: 0.000223\n",
            "Epoch [157], Train Loss: 0.000141, Val Loss: 0.000215\n",
            "Epoch [158], Train Loss: 0.000143, Val Loss: 0.000213\n",
            "Epoch [159], Train Loss: 0.000143, Val Loss: 0.000212\n",
            "Epoch [160], Train Loss: 0.000141, Val Loss: 0.000243\n",
            "Epoch [161], Train Loss: 0.000142, Val Loss: 0.000212\n",
            "Epoch [162], Train Loss: 0.000143, Val Loss: 0.000215\n",
            "Epoch [163], Train Loss: 0.000144, Val Loss: 0.000215\n",
            "Epoch [164], Train Loss: 0.000142, Val Loss: 0.000211\n",
            "Epoch [165], Train Loss: 0.000141, Val Loss: 0.000214\n",
            "Epoch [166], Train Loss: 0.000141, Val Loss: 0.000218\n",
            "Epoch [167], Train Loss: 0.000151, Val Loss: 0.000211\n",
            "Epoch [168], Train Loss: 0.000138, Val Loss: 0.000221\n",
            "Epoch [169], Train Loss: 0.000140, Val Loss: 0.000221\n",
            "Epoch [170], Train Loss: 0.000141, Val Loss: 0.000212\n",
            "Epoch [171], Train Loss: 0.000140, Val Loss: 0.000212\n",
            "Epoch [172], Train Loss: 0.000139, Val Loss: 0.000250\n",
            "Epoch [173], Train Loss: 0.000147, Val Loss: 0.000219\n",
            "Epoch [174], Train Loss: 0.000146, Val Loss: 0.000209\n",
            "Epoch [175], Train Loss: 0.000137, Val Loss: 0.000235\n",
            "Epoch [176], Train Loss: 0.000139, Val Loss: 0.000212\n",
            "Epoch [177], Train Loss: 0.000148, Val Loss: 0.000259\n",
            "Epoch [178], Train Loss: 0.000141, Val Loss: 0.000206\n",
            "Epoch [179], Train Loss: 0.000140, Val Loss: 0.000213\n",
            "Epoch [180], Train Loss: 0.000138, Val Loss: 0.000209\n",
            "Epoch [181], Train Loss: 0.000138, Val Loss: 0.000219\n",
            "Epoch [182], Train Loss: 0.000136, Val Loss: 0.000210\n",
            "Epoch [183], Train Loss: 0.000143, Val Loss: 0.000209\n",
            "Epoch [184], Train Loss: 0.000137, Val Loss: 0.000227\n",
            "Epoch [185], Train Loss: 0.000139, Val Loss: 0.000217\n",
            "Epoch [186], Train Loss: 0.000138, Val Loss: 0.000207\n",
            "Epoch [187], Train Loss: 0.000136, Val Loss: 0.000216\n",
            "Epoch [188], Train Loss: 0.000139, Val Loss: 0.000209\n",
            "Epoch [189], Train Loss: 0.000139, Val Loss: 0.000257\n",
            "Epoch [190], Train Loss: 0.000139, Val Loss: 0.000206\n",
            "Epoch [191], Train Loss: 0.000139, Val Loss: 0.000219\n",
            "Epoch [192], Train Loss: 0.000136, Val Loss: 0.000211\n",
            "Epoch [193], Train Loss: 0.000140, Val Loss: 0.000208\n",
            "Epoch [194], Train Loss: 0.000136, Val Loss: 0.000211\n",
            "Epoch [195], Train Loss: 0.000134, Val Loss: 0.000208\n",
            "Epoch [196], Train Loss: 0.000137, Val Loss: 0.000221\n",
            "Epoch [197], Train Loss: 0.000139, Val Loss: 0.000204\n",
            "Epoch [198], Train Loss: 0.000135, Val Loss: 0.000205\n",
            "Epoch [199], Train Loss: 0.000137, Val Loss: 0.000206\n",
            "Epoch [200], Train Loss: 0.000133, Val Loss: 0.000222\n",
            "Epoch [201], Train Loss: 0.000136, Val Loss: 0.000209\n",
            "Epoch [202], Train Loss: 0.000138, Val Loss: 0.000205\n",
            "Epoch [203], Train Loss: 0.000135, Val Loss: 0.000204\n",
            "Epoch [204], Train Loss: 0.000137, Val Loss: 0.000202\n",
            "Epoch [205], Train Loss: 0.000134, Val Loss: 0.000203\n",
            "Epoch [206], Train Loss: 0.000138, Val Loss: 0.000215\n",
            "Epoch [207], Train Loss: 0.000136, Val Loss: 0.000202\n",
            "Epoch [208], Train Loss: 0.000132, Val Loss: 0.000211\n",
            "Epoch [209], Train Loss: 0.000136, Val Loss: 0.000200\n",
            "Epoch [210], Train Loss: 0.000133, Val Loss: 0.000219\n",
            "Epoch [211], Train Loss: 0.000133, Val Loss: 0.000206\n",
            "Epoch [212], Train Loss: 0.000140, Val Loss: 0.000214\n",
            "Epoch [213], Train Loss: 0.000135, Val Loss: 0.000209\n",
            "Epoch [214], Train Loss: 0.000137, Val Loss: 0.000205\n",
            "Epoch [215], Train Loss: 0.000140, Val Loss: 0.000203\n",
            "Epoch [216], Train Loss: 0.000130, Val Loss: 0.000204\n",
            "Epoch [217], Train Loss: 0.000137, Val Loss: 0.000201\n",
            "Epoch [218], Train Loss: 0.000135, Val Loss: 0.000201\n",
            "Epoch [219], Train Loss: 0.000134, Val Loss: 0.000202\n",
            "Epoch [220], Train Loss: 0.000133, Val Loss: 0.000208\n",
            "Epoch [221], Train Loss: 0.000130, Val Loss: 0.000200\n",
            "Epoch [222], Train Loss: 0.000132, Val Loss: 0.000224\n",
            "Epoch [223], Train Loss: 0.000132, Val Loss: 0.000201\n",
            "Epoch [224], Train Loss: 0.000131, Val Loss: 0.000226\n",
            "Epoch [225], Train Loss: 0.000132, Val Loss: 0.000202\n",
            "Epoch [226], Train Loss: 0.000137, Val Loss: 0.000200\n",
            "Epoch [227], Train Loss: 0.000131, Val Loss: 0.000212\n",
            "Epoch [228], Train Loss: 0.000135, Val Loss: 0.000196\n",
            "Epoch [229], Train Loss: 0.000133, Val Loss: 0.000199\n",
            "Epoch [230], Train Loss: 0.000135, Val Loss: 0.000212\n",
            "Epoch [231], Train Loss: 0.000131, Val Loss: 0.000198\n",
            "Epoch [232], Train Loss: 0.000135, Val Loss: 0.000203\n",
            "Epoch [233], Train Loss: 0.000143, Val Loss: 0.000197\n",
            "Epoch [234], Train Loss: 0.000134, Val Loss: 0.000200\n",
            "Epoch [235], Train Loss: 0.000129, Val Loss: 0.000197\n",
            "Epoch [236], Train Loss: 0.000134, Val Loss: 0.000210\n",
            "Epoch [237], Train Loss: 0.000135, Val Loss: 0.000205\n",
            "Epoch [238], Train Loss: 0.000129, Val Loss: 0.000200\n",
            "Epoch [239], Train Loss: 0.000132, Val Loss: 0.000199\n",
            "Epoch [240], Train Loss: 0.000132, Val Loss: 0.000195\n",
            "Epoch [241], Train Loss: 0.000129, Val Loss: 0.000199\n",
            "Epoch [242], Train Loss: 0.000132, Val Loss: 0.000205\n",
            "Epoch [243], Train Loss: 0.000137, Val Loss: 0.000201\n",
            "Epoch [244], Train Loss: 0.000127, Val Loss: 0.000197\n",
            "Epoch [245], Train Loss: 0.000130, Val Loss: 0.000196\n",
            "Epoch [246], Train Loss: 0.000129, Val Loss: 0.000207\n",
            "Epoch [247], Train Loss: 0.000131, Val Loss: 0.000199\n",
            "Epoch [248], Train Loss: 0.000131, Val Loss: 0.000200\n",
            "Epoch [249], Train Loss: 0.000130, Val Loss: 0.000199\n",
            "Epoch [250], Train Loss: 0.000129, Val Loss: 0.000196\n",
            "Epoch [251], Train Loss: 0.000128, Val Loss: 0.000195\n",
            "Epoch [252], Train Loss: 0.000129, Val Loss: 0.000200\n",
            "Epoch [253], Train Loss: 0.000132, Val Loss: 0.000200\n",
            "Epoch [254], Train Loss: 0.000133, Val Loss: 0.000206\n",
            "Epoch [255], Train Loss: 0.000129, Val Loss: 0.000201\n",
            "Epoch [256], Train Loss: 0.000131, Val Loss: 0.000192\n",
            "Epoch [257], Train Loss: 0.000130, Val Loss: 0.000199\n",
            "Epoch [258], Train Loss: 0.000132, Val Loss: 0.000213\n",
            "Epoch [259], Train Loss: 0.000131, Val Loss: 0.000193\n",
            "Epoch [260], Train Loss: 0.000131, Val Loss: 0.000195\n",
            "Epoch [261], Train Loss: 0.000128, Val Loss: 0.000190\n",
            "Epoch [262], Train Loss: 0.000132, Val Loss: 0.000190\n",
            "Epoch [263], Train Loss: 0.000133, Val Loss: 0.000234\n",
            "Epoch [264], Train Loss: 0.000130, Val Loss: 0.000191\n",
            "Epoch [265], Train Loss: 0.000129, Val Loss: 0.000195\n",
            "Epoch [266], Train Loss: 0.000128, Val Loss: 0.000192\n",
            "Epoch [267], Train Loss: 0.000129, Val Loss: 0.000194\n",
            "Epoch [268], Train Loss: 0.000128, Val Loss: 0.000222\n",
            "Epoch [269], Train Loss: 0.000127, Val Loss: 0.000197\n",
            "Epoch [270], Train Loss: 0.000133, Val Loss: 0.000189\n",
            "Epoch [271], Train Loss: 0.000130, Val Loss: 0.000201\n",
            "Epoch [272], Train Loss: 0.000131, Val Loss: 0.000193\n",
            "Epoch [273], Train Loss: 0.000131, Val Loss: 0.000195\n",
            "Epoch [274], Train Loss: 0.000127, Val Loss: 0.000209\n",
            "Epoch [275], Train Loss: 0.000131, Val Loss: 0.000189\n",
            "Epoch [276], Train Loss: 0.000126, Val Loss: 0.000188\n",
            "Epoch [277], Train Loss: 0.000128, Val Loss: 0.000207\n",
            "Epoch [278], Train Loss: 0.000130, Val Loss: 0.000206\n",
            "Epoch [279], Train Loss: 0.000127, Val Loss: 0.000201\n",
            "Epoch [280], Train Loss: 0.000128, Val Loss: 0.000185\n",
            "Epoch [281], Train Loss: 0.000127, Val Loss: 0.000193\n",
            "Epoch [282], Train Loss: 0.000130, Val Loss: 0.000187\n",
            "Epoch [283], Train Loss: 0.000124, Val Loss: 0.000186\n",
            "Epoch [284], Train Loss: 0.000127, Val Loss: 0.000215\n",
            "Epoch [285], Train Loss: 0.000128, Val Loss: 0.000187\n",
            "Epoch [286], Train Loss: 0.000129, Val Loss: 0.000189\n",
            "Epoch [287], Train Loss: 0.000127, Val Loss: 0.000195\n",
            "Epoch [288], Train Loss: 0.000131, Val Loss: 0.000187\n",
            "Epoch [289], Train Loss: 0.000126, Val Loss: 0.000186\n",
            "Epoch [290], Train Loss: 0.000127, Val Loss: 0.000186\n",
            "Epoch [291], Train Loss: 0.000126, Val Loss: 0.000189\n",
            "Epoch [292], Train Loss: 0.000125, Val Loss: 0.000190\n",
            "Epoch [293], Train Loss: 0.000126, Val Loss: 0.000186\n",
            "Epoch [294], Train Loss: 0.000123, Val Loss: 0.000183\n",
            "Epoch [295], Train Loss: 0.000127, Val Loss: 0.000188\n",
            "Epoch [296], Train Loss: 0.000132, Val Loss: 0.000189\n",
            "Epoch [297], Train Loss: 0.000127, Val Loss: 0.000188\n",
            "Epoch [298], Train Loss: 0.000130, Val Loss: 0.000187\n",
            "Epoch [299], Train Loss: 0.000127, Val Loss: 0.000188\n",
            "Epoch [300], Train Loss: 0.000127, Val Loss: 0.000193\n",
            "Epoch [301], Train Loss: 0.000127, Val Loss: 0.000187\n",
            "Epoch [302], Train Loss: 0.000128, Val Loss: 0.000188\n",
            "Epoch [303], Train Loss: 0.000122, Val Loss: 0.000188\n",
            "Epoch [304], Train Loss: 0.000124, Val Loss: 0.000184\n",
            "Epoch [305], Train Loss: 0.000125, Val Loss: 0.000209\n",
            "Epoch [306], Train Loss: 0.000127, Val Loss: 0.000187\n",
            "Epoch [307], Train Loss: 0.000133, Val Loss: 0.000189\n",
            "Epoch [308], Train Loss: 0.000129, Val Loss: 0.000198\n",
            "Epoch [309], Train Loss: 0.000125, Val Loss: 0.000187\n",
            "Epoch [310], Train Loss: 0.000124, Val Loss: 0.000195\n",
            "Epoch [311], Train Loss: 0.000128, Val Loss: 0.000195\n",
            "Epoch [312], Train Loss: 0.000128, Val Loss: 0.000195\n",
            "Epoch [313], Train Loss: 0.000127, Val Loss: 0.000191\n",
            "Epoch [314], Train Loss: 0.000129, Val Loss: 0.000189\n",
            "Epoch [315], Train Loss: 0.000129, Val Loss: 0.000185\n",
            "Epoch [316], Train Loss: 0.000124, Val Loss: 0.000185\n",
            "Epoch [317], Train Loss: 0.000124, Val Loss: 0.000186\n",
            "Epoch [318], Train Loss: 0.000124, Val Loss: 0.000189\n",
            "Epoch [319], Train Loss: 0.000127, Val Loss: 0.000182\n",
            "Epoch [320], Train Loss: 0.000125, Val Loss: 0.000188\n",
            "Epoch [321], Train Loss: 0.000125, Val Loss: 0.000186\n",
            "Epoch [322], Train Loss: 0.000124, Val Loss: 0.000186\n",
            "Epoch [323], Train Loss: 0.000126, Val Loss: 0.000187\n",
            "Epoch [324], Train Loss: 0.000126, Val Loss: 0.000182\n",
            "Epoch [325], Train Loss: 0.000128, Val Loss: 0.000208\n",
            "Epoch [326], Train Loss: 0.000127, Val Loss: 0.000182\n",
            "Epoch [327], Train Loss: 0.000124, Val Loss: 0.000194\n",
            "Epoch [328], Train Loss: 0.000130, Val Loss: 0.000184\n",
            "Epoch [329], Train Loss: 0.000123, Val Loss: 0.000180\n",
            "Epoch [330], Train Loss: 0.000125, Val Loss: 0.000179\n",
            "Epoch [331], Train Loss: 0.000125, Val Loss: 0.000182\n",
            "Epoch [332], Train Loss: 0.000123, Val Loss: 0.000180\n",
            "Epoch [333], Train Loss: 0.000122, Val Loss: 0.000182\n",
            "Epoch [334], Train Loss: 0.000126, Val Loss: 0.000181\n",
            "Epoch [335], Train Loss: 0.000123, Val Loss: 0.000181\n",
            "Epoch [336], Train Loss: 0.000129, Val Loss: 0.000261\n",
            "Epoch [337], Train Loss: 0.000130, Val Loss: 0.000192\n",
            "Epoch [338], Train Loss: 0.000124, Val Loss: 0.000188\n",
            "Epoch [339], Train Loss: 0.000129, Val Loss: 0.000189\n",
            "Epoch [340], Train Loss: 0.000130, Val Loss: 0.000183\n",
            "Epoch [341], Train Loss: 0.000128, Val Loss: 0.000186\n",
            "Epoch [342], Train Loss: 0.000123, Val Loss: 0.000193\n",
            "Epoch [343], Train Loss: 0.000124, Val Loss: 0.000191\n",
            "Epoch [344], Train Loss: 0.000129, Val Loss: 0.000182\n",
            "Epoch [345], Train Loss: 0.000123, Val Loss: 0.000178\n",
            "Epoch [346], Train Loss: 0.000123, Val Loss: 0.000180\n",
            "Epoch [347], Train Loss: 0.000125, Val Loss: 0.000185\n",
            "Epoch [348], Train Loss: 0.000126, Val Loss: 0.000180\n",
            "Epoch [349], Train Loss: 0.000121, Val Loss: 0.000198\n",
            "Epoch [350], Train Loss: 0.000126, Val Loss: 0.000185\n",
            "Epoch [351], Train Loss: 0.000127, Val Loss: 0.000182\n",
            "Epoch [352], Train Loss: 0.000121, Val Loss: 0.000181\n",
            "Epoch [353], Train Loss: 0.000133, Val Loss: 0.000178\n",
            "Epoch [354], Train Loss: 0.000122, Val Loss: 0.000180\n",
            "Epoch [355], Train Loss: 0.000119, Val Loss: 0.000178\n",
            "Epoch [356], Train Loss: 0.000126, Val Loss: 0.000179\n",
            "Epoch [357], Train Loss: 0.000123, Val Loss: 0.000184\n",
            "Epoch [358], Train Loss: 0.000120, Val Loss: 0.000178\n",
            "Epoch [359], Train Loss: 0.000123, Val Loss: 0.000184\n",
            "Epoch [360], Train Loss: 0.000122, Val Loss: 0.000189\n",
            "Epoch [361], Train Loss: 0.000127, Val Loss: 0.000187\n",
            "Epoch [362], Train Loss: 0.000123, Val Loss: 0.000180\n",
            "Epoch [363], Train Loss: 0.000123, Val Loss: 0.000184\n",
            "Epoch [364], Train Loss: 0.000128, Val Loss: 0.000180\n",
            "Epoch [365], Train Loss: 0.000123, Val Loss: 0.000177\n",
            "Epoch [366], Train Loss: 0.000123, Val Loss: 0.000181\n",
            "Epoch [367], Train Loss: 0.000122, Val Loss: 0.000182\n",
            "Epoch [368], Train Loss: 0.000126, Val Loss: 0.000185\n",
            "Epoch [369], Train Loss: 0.000122, Val Loss: 0.000180\n",
            "Epoch [370], Train Loss: 0.000122, Val Loss: 0.000182\n",
            "Epoch [371], Train Loss: 0.000121, Val Loss: 0.000180\n",
            "Epoch [372], Train Loss: 0.000122, Val Loss: 0.000194\n",
            "Epoch [373], Train Loss: 0.000127, Val Loss: 0.000177\n",
            "Epoch [374], Train Loss: 0.000119, Val Loss: 0.000194\n",
            "Epoch [375], Train Loss: 0.000124, Val Loss: 0.000189\n",
            "Epoch [376], Train Loss: 0.000121, Val Loss: 0.000183\n",
            "Epoch [377], Train Loss: 0.000122, Val Loss: 0.000191\n",
            "Epoch [378], Train Loss: 0.000124, Val Loss: 0.000179\n",
            "Epoch [379], Train Loss: 0.000133, Val Loss: 0.000213\n",
            "Epoch [380], Train Loss: 0.000129, Val Loss: 0.000205\n",
            "Epoch [381], Train Loss: 0.000123, Val Loss: 0.000180\n",
            "Epoch [382], Train Loss: 0.000120, Val Loss: 0.000188\n",
            "Epoch [383], Train Loss: 0.000124, Val Loss: 0.000181\n",
            "Epoch [384], Train Loss: 0.000120, Val Loss: 0.000175\n",
            "Epoch [385], Train Loss: 0.000120, Val Loss: 0.000180\n",
            "Epoch [386], Train Loss: 0.000123, Val Loss: 0.000178\n",
            "Epoch [387], Train Loss: 0.000120, Val Loss: 0.000178\n",
            "Epoch [388], Train Loss: 0.000120, Val Loss: 0.000186\n",
            "Epoch [389], Train Loss: 0.000124, Val Loss: 0.000190\n",
            "Epoch [390], Train Loss: 0.000123, Val Loss: 0.000180\n",
            "Epoch [391], Train Loss: 0.000127, Val Loss: 0.000177\n",
            "Epoch [392], Train Loss: 0.000126, Val Loss: 0.000201\n",
            "Epoch [393], Train Loss: 0.000121, Val Loss: 0.000179\n",
            "Epoch [394], Train Loss: 0.000124, Val Loss: 0.000178\n",
            "Epoch [395], Train Loss: 0.000122, Val Loss: 0.000185\n",
            "Epoch [396], Train Loss: 0.000124, Val Loss: 0.000176\n",
            "Epoch [397], Train Loss: 0.000122, Val Loss: 0.000186\n",
            "Epoch [398], Train Loss: 0.000120, Val Loss: 0.000179\n",
            "Epoch [399], Train Loss: 0.000122, Val Loss: 0.000180\n",
            "Epoch [400], Train Loss: 0.000124, Val Loss: 0.000183\n",
            "Epoch [401], Train Loss: 0.000120, Val Loss: 0.000182\n",
            "Epoch [402], Train Loss: 0.000121, Val Loss: 0.000186\n",
            "Epoch [403], Train Loss: 0.000124, Val Loss: 0.000201\n",
            "Epoch [404], Train Loss: 0.000122, Val Loss: 0.000175\n",
            "Epoch [405], Train Loss: 0.000121, Val Loss: 0.000182\n",
            "Epoch [406], Train Loss: 0.000119, Val Loss: 0.000180\n",
            "Epoch [407], Train Loss: 0.000125, Val Loss: 0.000188\n",
            "Epoch [408], Train Loss: 0.000121, Val Loss: 0.000194\n",
            "Epoch [409], Train Loss: 0.000125, Val Loss: 0.000185\n",
            "Epoch [410], Train Loss: 0.000122, Val Loss: 0.000184\n",
            "Epoch [411], Train Loss: 0.000122, Val Loss: 0.000190\n",
            "Epoch [412], Train Loss: 0.000127, Val Loss: 0.000186\n",
            "Epoch [413], Train Loss: 0.000124, Val Loss: 0.000174\n",
            "Epoch [414], Train Loss: 0.000117, Val Loss: 0.000177\n",
            "Epoch [415], Train Loss: 0.000120, Val Loss: 0.000176\n",
            "Epoch [416], Train Loss: 0.000117, Val Loss: 0.000178\n",
            "Epoch [417], Train Loss: 0.000120, Val Loss: 0.000175\n",
            "Epoch [418], Train Loss: 0.000123, Val Loss: 0.000180\n",
            "Epoch [419], Train Loss: 0.000125, Val Loss: 0.000197\n",
            "Epoch [420], Train Loss: 0.000123, Val Loss: 0.000185\n",
            "Epoch [421], Train Loss: 0.000123, Val Loss: 0.000200\n",
            "Epoch [422], Train Loss: 0.000123, Val Loss: 0.000189\n",
            "Epoch [423], Train Loss: 0.000121, Val Loss: 0.000185\n",
            "Epoch [424], Train Loss: 0.000119, Val Loss: 0.000175\n",
            "Early stopping after 424 epochs.\n",
            "Iteration 3 Metrics: MSE=0.000175, RMSE=0.013210, MAE=0.002570, R2=0.986860, Corr=0.993431\n",
            "s_full [ -0.35583115   0.         -83.06515503   8.1570158 ]\n",
            "s_full [  0.11174086   0.         -52.17671204   4.30875015]\n",
            "s_full [-0.12553236  0.         54.94116211 -7.23113823]\n",
            "s_full [  1.02792478   0.          64.1767807  -24.42121124]\n",
            "s_full [-2.98615899e-02  0.00000000e+00 -5.21693268e+01  4.36000919e+00]\n",
            "s_full [  0.99729538   0.          81.44116211 -27.0769825 ]\n",
            "s_full [-5.66435717e-02  0.00000000e+00 -6.24541779e+01  2.35244131e+00]\n",
            "s_full [ -0.10016627   0.         -51.77672958   3.81543112]\n",
            "s_full [ -0.57466537   0.         -86.77778625  24.99356079]\n",
            "s_full [-0.10246491  0.         55.52347183 -3.78972888]\n",
            "feasible states 0\n",
            "\n",
            "=== DAgger Iteration 4 ===\n",
            "Epoch [1], Train Loss: 0.000154, Val Loss: 0.000049\n",
            "Epoch [2], Train Loss: 0.000157, Val Loss: 0.000063\n",
            "Epoch [3], Train Loss: 0.000160, Val Loss: 0.000039\n",
            "Epoch [4], Train Loss: 0.000155, Val Loss: 0.000041\n",
            "Epoch [5], Train Loss: 0.000153, Val Loss: 0.000039\n",
            "Epoch [6], Train Loss: 0.000150, Val Loss: 0.000040\n",
            "Epoch [7], Train Loss: 0.000154, Val Loss: 0.000040\n",
            "Epoch [8], Train Loss: 0.000153, Val Loss: 0.000040\n",
            "Epoch [9], Train Loss: 0.000160, Val Loss: 0.000045\n",
            "Epoch [10], Train Loss: 0.000153, Val Loss: 0.000038\n",
            "Epoch [11], Train Loss: 0.000158, Val Loss: 0.000040\n",
            "Epoch [12], Train Loss: 0.000150, Val Loss: 0.000048\n",
            "Epoch [13], Train Loss: 0.000156, Val Loss: 0.000079\n",
            "Epoch [14], Train Loss: 0.000150, Val Loss: 0.000044\n",
            "Epoch [15], Train Loss: 0.000153, Val Loss: 0.000044\n",
            "Epoch [16], Train Loss: 0.000151, Val Loss: 0.000047\n",
            "Epoch [17], Train Loss: 0.000158, Val Loss: 0.000048\n",
            "Epoch [18], Train Loss: 0.000148, Val Loss: 0.000043\n",
            "Epoch [19], Train Loss: 0.000148, Val Loss: 0.000042\n",
            "Epoch [20], Train Loss: 0.000157, Val Loss: 0.000041\n",
            "Epoch [21], Train Loss: 0.000146, Val Loss: 0.000041\n",
            "Epoch [22], Train Loss: 0.000151, Val Loss: 0.000045\n",
            "Epoch [23], Train Loss: 0.000150, Val Loss: 0.000039\n",
            "Epoch [24], Train Loss: 0.000153, Val Loss: 0.000041\n",
            "Epoch [25], Train Loss: 0.000150, Val Loss: 0.000040\n",
            "Epoch [26], Train Loss: 0.000150, Val Loss: 0.000048\n",
            "Epoch [27], Train Loss: 0.000154, Val Loss: 0.000117\n",
            "Epoch [28], Train Loss: 0.000153, Val Loss: 0.000057\n",
            "Epoch [29], Train Loss: 0.000151, Val Loss: 0.000041\n",
            "Epoch [30], Train Loss: 0.000146, Val Loss: 0.000048\n",
            "Epoch [31], Train Loss: 0.000151, Val Loss: 0.000043\n",
            "Epoch [32], Train Loss: 0.000151, Val Loss: 0.000054\n",
            "Epoch [33], Train Loss: 0.000158, Val Loss: 0.000038\n",
            "Epoch [34], Train Loss: 0.000148, Val Loss: 0.000039\n",
            "Epoch [35], Train Loss: 0.000147, Val Loss: 0.000040\n",
            "Epoch [36], Train Loss: 0.000146, Val Loss: 0.000042\n",
            "Epoch [37], Train Loss: 0.000146, Val Loss: 0.000052\n",
            "Epoch [38], Train Loss: 0.000152, Val Loss: 0.000040\n",
            "Epoch [39], Train Loss: 0.000148, Val Loss: 0.000044\n",
            "Epoch [40], Train Loss: 0.000147, Val Loss: 0.000046\n",
            "Epoch [41], Train Loss: 0.000147, Val Loss: 0.000050\n",
            "Epoch [42], Train Loss: 0.000148, Val Loss: 0.000042\n",
            "Epoch [43], Train Loss: 0.000145, Val Loss: 0.000053\n",
            "Epoch [44], Train Loss: 0.000150, Val Loss: 0.000056\n",
            "Epoch [45], Train Loss: 0.000154, Val Loss: 0.000044\n",
            "Epoch [46], Train Loss: 0.000146, Val Loss: 0.000051\n",
            "Epoch [47], Train Loss: 0.000146, Val Loss: 0.000041\n",
            "Epoch [48], Train Loss: 0.000146, Val Loss: 0.000039\n",
            "Epoch [49], Train Loss: 0.000142, Val Loss: 0.000041\n",
            "Epoch [50], Train Loss: 0.000144, Val Loss: 0.000040\n",
            "Early stopping after 50 epochs.\n",
            "Iteration 4 Metrics: MSE=0.000040, RMSE=0.006335, MAE=0.002324, R2=0.996737, Corr=0.998388\n",
            "s_full [  1.4464277    0.          56.20454407 -27.86002541]\n",
            "s_full [  1.82423699   0.          58.38337708 -31.27039337]\n",
            "s_full [  1.41773605   0.          50.0952034  -24.71361542]\n",
            "s_full [  0.21290442   0.          79.66641235 -11.52626991]\n",
            "s_full [  1.00174773   0.          54.50135422 -21.92658806]\n",
            "s_full [ 3.10743507e-02  0.00000000e+00 -6.43785934e+01  5.01209641e+00]\n",
            "s_full [  0.14721884   0.         -78.61109924   9.24101448]\n",
            "s_full [ -0.67922199   0.         -90.49584198  25.59216881]\n",
            "s_full [ 4.24488522e-02  0.00000000e+00  7.33516922e+01 -1.10718174e+01]\n",
            "feasible states 50\n",
            "\n",
            "=== DAgger Iteration 5 ===\n",
            "Epoch [1], Train Loss: 0.000329, Val Loss: 0.000124\n",
            "Epoch [2], Train Loss: 0.000260, Val Loss: 0.000128\n",
            "Epoch [3], Train Loss: 0.000272, Val Loss: 0.000125\n",
            "Epoch [4], Train Loss: 0.000210, Val Loss: 0.000362\n",
            "Epoch [5], Train Loss: 0.000240, Val Loss: 0.000127\n",
            "Epoch [6], Train Loss: 0.000209, Val Loss: 0.000129\n",
            "Epoch [7], Train Loss: 0.000214, Val Loss: 0.000125\n",
            "Epoch [8], Train Loss: 0.000203, Val Loss: 0.000150\n",
            "Epoch [9], Train Loss: 0.000205, Val Loss: 0.000128\n",
            "Epoch [10], Train Loss: 0.000191, Val Loss: 0.000130\n",
            "Epoch [11], Train Loss: 0.000190, Val Loss: 0.000124\n",
            "Epoch [12], Train Loss: 0.000194, Val Loss: 0.000133\n",
            "Epoch [13], Train Loss: 0.000186, Val Loss: 0.000131\n",
            "Epoch [14], Train Loss: 0.000184, Val Loss: 0.000143\n",
            "Epoch [15], Train Loss: 0.000179, Val Loss: 0.000137\n",
            "Epoch [16], Train Loss: 0.000177, Val Loss: 0.000138\n",
            "Epoch [17], Train Loss: 0.000176, Val Loss: 0.000132\n",
            "Epoch [18], Train Loss: 0.000175, Val Loss: 0.000137\n",
            "Epoch [19], Train Loss: 0.000167, Val Loss: 0.000128\n",
            "Epoch [20], Train Loss: 0.000166, Val Loss: 0.000140\n",
            "Epoch [21], Train Loss: 0.000163, Val Loss: 0.000133\n",
            "Epoch [22], Train Loss: 0.000169, Val Loss: 0.000168\n",
            "Epoch [23], Train Loss: 0.000167, Val Loss: 0.000143\n",
            "Epoch [24], Train Loss: 0.000168, Val Loss: 0.000128\n",
            "Epoch [25], Train Loss: 0.000164, Val Loss: 0.000127\n",
            "Epoch [26], Train Loss: 0.000159, Val Loss: 0.000131\n",
            "Epoch [27], Train Loss: 0.000159, Val Loss: 0.000129\n",
            "Epoch [28], Train Loss: 0.000163, Val Loss: 0.000128\n",
            "Epoch [29], Train Loss: 0.000165, Val Loss: 0.000130\n",
            "Epoch [30], Train Loss: 0.000155, Val Loss: 0.000127\n",
            "Epoch [31], Train Loss: 0.000162, Val Loss: 0.000134\n",
            "Epoch [32], Train Loss: 0.000153, Val Loss: 0.000126\n",
            "Epoch [33], Train Loss: 0.000152, Val Loss: 0.000129\n",
            "Epoch [34], Train Loss: 0.000151, Val Loss: 0.000131\n",
            "Epoch [35], Train Loss: 0.000149, Val Loss: 0.000136\n",
            "Epoch [36], Train Loss: 0.000154, Val Loss: 0.000132\n",
            "Epoch [37], Train Loss: 0.000152, Val Loss: 0.000132\n",
            "Epoch [38], Train Loss: 0.000149, Val Loss: 0.000135\n",
            "Epoch [39], Train Loss: 0.000150, Val Loss: 0.000130\n",
            "Epoch [40], Train Loss: 0.000150, Val Loss: 0.000148\n",
            "Epoch [41], Train Loss: 0.000152, Val Loss: 0.000144\n",
            "Early stopping after 41 epochs.\n",
            "Iteration 5 Metrics: MSE=0.000144, RMSE=0.011993, MAE=0.004631, R2=0.988917, Corr=0.994852\n",
            "s_full [ -0.13414057   0.         -90.66065216  15.94967175]\n",
            "s_full [-0.24332736  0.         57.0293808  -1.04010582]\n",
            "s_full [ -0.33063594   0.         -88.87785339  22.59296989]\n",
            "s_full [-0.10830057  0.         63.98251343 -2.89278412]\n",
            "s_full [ 1.27136125e-03  0.00000000e+00 -5.01434822e+01 -2.01824144e-01]\n",
            "s_full [  0.53637785   0.          57.8600769  -18.51035881]\n",
            "s_full [  0.7624557    0.          55.27866364 -26.36539268]\n",
            "s_full [-0.19781883  0.         63.71961212 -3.9524858 ]\n",
            "s_full [  0.57890791   0.          73.47717285 -22.93784142]\n",
            "s_full [-0.10922851  0.         54.39309311 10.0312891 ]\n",
            "feasible states 0\n",
            "\n",
            "=== DAgger Iteration 6 ===\n",
            "Epoch [1], Train Loss: 0.000146, Val Loss: 0.000161\n",
            "Epoch [2], Train Loss: 0.000150, Val Loss: 0.000147\n",
            "Epoch [3], Train Loss: 0.000151, Val Loss: 0.000134\n",
            "Epoch [4], Train Loss: 0.000157, Val Loss: 0.000147\n",
            "Epoch [5], Train Loss: 0.000144, Val Loss: 0.000127\n",
            "Epoch [6], Train Loss: 0.000144, Val Loss: 0.000134\n",
            "Epoch [7], Train Loss: 0.000148, Val Loss: 0.000132\n",
            "Epoch [8], Train Loss: 0.000145, Val Loss: 0.000128\n",
            "Epoch [9], Train Loss: 0.000145, Val Loss: 0.000131\n",
            "Epoch [10], Train Loss: 0.000144, Val Loss: 0.000130\n",
            "Epoch [11], Train Loss: 0.000150, Val Loss: 0.000132\n",
            "Epoch [12], Train Loss: 0.000142, Val Loss: 0.000143\n",
            "Epoch [13], Train Loss: 0.000140, Val Loss: 0.000129\n",
            "Epoch [14], Train Loss: 0.000139, Val Loss: 0.000134\n",
            "Epoch [15], Train Loss: 0.000138, Val Loss: 0.000131\n",
            "Epoch [16], Train Loss: 0.000142, Val Loss: 0.000137\n",
            "Epoch [17], Train Loss: 0.000151, Val Loss: 0.000137\n",
            "Epoch [18], Train Loss: 0.000139, Val Loss: 0.000139\n",
            "Epoch [19], Train Loss: 0.000140, Val Loss: 0.000146\n",
            "Epoch [20], Train Loss: 0.000144, Val Loss: 0.000138\n",
            "Epoch [21], Train Loss: 0.000137, Val Loss: 0.000130\n",
            "Epoch [22], Train Loss: 0.000138, Val Loss: 0.000147\n",
            "Epoch [23], Train Loss: 0.000143, Val Loss: 0.000138\n",
            "Epoch [24], Train Loss: 0.000144, Val Loss: 0.000136\n",
            "Epoch [25], Train Loss: 0.000139, Val Loss: 0.000133\n",
            "Epoch [26], Train Loss: 0.000139, Val Loss: 0.000130\n",
            "Epoch [27], Train Loss: 0.000144, Val Loss: 0.000148\n",
            "Epoch [28], Train Loss: 0.000142, Val Loss: 0.000138\n",
            "Epoch [29], Train Loss: 0.000138, Val Loss: 0.000129\n",
            "Epoch [30], Train Loss: 0.000136, Val Loss: 0.000135\n",
            "Epoch [31], Train Loss: 0.000139, Val Loss: 0.000134\n",
            "Epoch [32], Train Loss: 0.000138, Val Loss: 0.000131\n",
            "Epoch [33], Train Loss: 0.000136, Val Loss: 0.000137\n",
            "Epoch [34], Train Loss: 0.000139, Val Loss: 0.000133\n",
            "Epoch [35], Train Loss: 0.000143, Val Loss: 0.000136\n",
            "Epoch [36], Train Loss: 0.000137, Val Loss: 0.000136\n",
            "Epoch [37], Train Loss: 0.000138, Val Loss: 0.000140\n",
            "Epoch [38], Train Loss: 0.000139, Val Loss: 0.000137\n",
            "Epoch [39], Train Loss: 0.000134, Val Loss: 0.000153\n",
            "Epoch [40], Train Loss: 0.000138, Val Loss: 0.000132\n",
            "Epoch [41], Train Loss: 0.000133, Val Loss: 0.000132\n",
            "Epoch [42], Train Loss: 0.000135, Val Loss: 0.000130\n",
            "Epoch [43], Train Loss: 0.000134, Val Loss: 0.000139\n",
            "Epoch [44], Train Loss: 0.000133, Val Loss: 0.000136\n",
            "Epoch [45], Train Loss: 0.000134, Val Loss: 0.000132\n",
            "Early stopping after 45 epochs.\n",
            "Iteration 6 Metrics: MSE=0.000132, RMSE=0.011483, MAE=0.002500, R2=0.988774, Corr=0.994373\n",
            "s_full [  1.2259233   0.         56.144104  -26.5189743]\n",
            "s_full [  0.30085164   0.          77.5667038  -18.44960976]\n",
            "s_full [  0.51859301   0.          86.25159454 -23.97332191]\n",
            "s_full [-0.31525764  0.         77.86824036 -3.76294756]\n",
            "s_full [  0.2342383    0.          78.17601013 -29.61653519]\n",
            "s_full [  1.58324611   0.         -70.28668213  18.41222191]\n",
            "s_full [-0.18709543  0.         50.18984604  1.55064678]\n",
            "s_full [  0.84761572   0.          68.29328156 -32.0133667 ]\n",
            "s_full [  1.79943454   0.          50.27297592 -26.72175598]\n",
            "s_full [  0.55266052   0.         -57.07817459  32.17747879]\n",
            "feasible states 0\n",
            "\n",
            "=== DAgger Iteration 7 ===\n",
            "Epoch [1], Train Loss: 0.000156, Val Loss: 0.000052\n",
            "Epoch [2], Train Loss: 0.000152, Val Loss: 0.000055\n",
            "Epoch [3], Train Loss: 0.000154, Val Loss: 0.000064\n",
            "Epoch [4], Train Loss: 0.000161, Val Loss: 0.000051\n",
            "Epoch [5], Train Loss: 0.000153, Val Loss: 0.000061\n",
            "Epoch [6], Train Loss: 0.000164, Val Loss: 0.000053\n",
            "Epoch [7], Train Loss: 0.000156, Val Loss: 0.000057\n",
            "Epoch [8], Train Loss: 0.000151, Val Loss: 0.000053\n",
            "Epoch [9], Train Loss: 0.000154, Val Loss: 0.000062\n",
            "Epoch [10], Train Loss: 0.000153, Val Loss: 0.000054\n",
            "Epoch [11], Train Loss: 0.000152, Val Loss: 0.000087\n",
            "Epoch [12], Train Loss: 0.000150, Val Loss: 0.000054\n",
            "Epoch [13], Train Loss: 0.000152, Val Loss: 0.000056\n",
            "Epoch [14], Train Loss: 0.000154, Val Loss: 0.000053\n",
            "Epoch [15], Train Loss: 0.000157, Val Loss: 0.000057\n",
            "Epoch [16], Train Loss: 0.000149, Val Loss: 0.000053\n",
            "Epoch [17], Train Loss: 0.000149, Val Loss: 0.000053\n",
            "Epoch [18], Train Loss: 0.000151, Val Loss: 0.000057\n",
            "Epoch [19], Train Loss: 0.000152, Val Loss: 0.000070\n",
            "Epoch [20], Train Loss: 0.000148, Val Loss: 0.000053\n",
            "Epoch [21], Train Loss: 0.000155, Val Loss: 0.000065\n",
            "Epoch [22], Train Loss: 0.000153, Val Loss: 0.000062\n",
            "Epoch [23], Train Loss: 0.000152, Val Loss: 0.000055\n",
            "Epoch [24], Train Loss: 0.000147, Val Loss: 0.000065\n",
            "Epoch [25], Train Loss: 0.000153, Val Loss: 0.000060\n",
            "Epoch [26], Train Loss: 0.000150, Val Loss: 0.000057\n",
            "Epoch [27], Train Loss: 0.000146, Val Loss: 0.000054\n",
            "Epoch [28], Train Loss: 0.000150, Val Loss: 0.000071\n",
            "Epoch [29], Train Loss: 0.000151, Val Loss: 0.000056\n",
            "Epoch [30], Train Loss: 0.000146, Val Loss: 0.000060\n",
            "Epoch [31], Train Loss: 0.000150, Val Loss: 0.000053\n",
            "Epoch [32], Train Loss: 0.000147, Val Loss: 0.000058\n",
            "Epoch [33], Train Loss: 0.000147, Val Loss: 0.000062\n",
            "Epoch [34], Train Loss: 0.000144, Val Loss: 0.000074\n",
            "Epoch [35], Train Loss: 0.000149, Val Loss: 0.000060\n",
            "Epoch [36], Train Loss: 0.000145, Val Loss: 0.000059\n",
            "Epoch [37], Train Loss: 0.000149, Val Loss: 0.000101\n",
            "Epoch [38], Train Loss: 0.000157, Val Loss: 0.000096\n",
            "Epoch [39], Train Loss: 0.000150, Val Loss: 0.000058\n",
            "Epoch [40], Train Loss: 0.000142, Val Loss: 0.000055\n",
            "Epoch [41], Train Loss: 0.000144, Val Loss: 0.000061\n",
            "Epoch [42], Train Loss: 0.000143, Val Loss: 0.000057\n",
            "Epoch [43], Train Loss: 0.000144, Val Loss: 0.000065\n",
            "Epoch [44], Train Loss: 0.000143, Val Loss: 0.000065\n",
            "Early stopping after 44 epochs.\n",
            "Iteration 7 Metrics: MSE=0.000065, RMSE=0.008045, MAE=0.003083, R2=0.993594, Corr=0.997068\n",
            "s_full [ 3.03925630e-02  0.00000000e+00 -7.21628571e+01  8.16021061e+00]\n",
            "s_full [  0.22916816   0.          58.72604752 -23.45017242]\n",
            "s_full [  0.89946854   0.          53.41622162 -20.56075478]\n",
            "s_full [  0.28777394   0.         -83.86947632   6.06626129]\n",
            "s_full [ -0.74055421   0.         -50.12534714  30.9631691 ]\n",
            "s_full [  1.41056907   0.          59.90219498 -28.75745392]\n",
            "s_full [  0.86792648   0.         -64.68875122  13.87812996]\n",
            "s_full [ -0.21712701   0.         -84.01576233  17.26542282]\n",
            "s_full [ -0.2867687    0.         -89.86247253  22.46356392]\n",
            "s_full [  1.03442383   0.          63.01348877 -23.96733665]\n",
            "feasible states 0\n",
            "\n",
            "=== DAgger Iteration 8 ===\n",
            "Epoch [1], Train Loss: 0.000150, Val Loss: 0.000083\n",
            "Epoch [2], Train Loss: 0.000139, Val Loss: 0.000092\n",
            "Epoch [3], Train Loss: 0.000137, Val Loss: 0.000105\n",
            "Epoch [4], Train Loss: 0.000138, Val Loss: 0.000101\n",
            "Epoch [5], Train Loss: 0.000137, Val Loss: 0.000089\n",
            "Epoch [6], Train Loss: 0.000134, Val Loss: 0.000096\n",
            "Epoch [7], Train Loss: 0.000133, Val Loss: 0.000092\n",
            "Epoch [8], Train Loss: 0.000132, Val Loss: 0.000097\n",
            "Epoch [9], Train Loss: 0.000133, Val Loss: 0.000101\n",
            "Epoch [10], Train Loss: 0.000132, Val Loss: 0.000098\n",
            "Epoch [11], Train Loss: 0.000131, Val Loss: 0.000099\n",
            "Epoch [12], Train Loss: 0.000133, Val Loss: 0.000103\n",
            "Epoch [13], Train Loss: 0.000131, Val Loss: 0.000117\n",
            "Epoch [14], Train Loss: 0.000131, Val Loss: 0.000110\n",
            "Epoch [15], Train Loss: 0.000136, Val Loss: 0.000110\n",
            "Epoch [16], Train Loss: 0.000130, Val Loss: 0.000102\n",
            "Epoch [17], Train Loss: 0.000130, Val Loss: 0.000108\n",
            "Epoch [18], Train Loss: 0.000131, Val Loss: 0.000106\n",
            "Epoch [19], Train Loss: 0.000130, Val Loss: 0.000117\n",
            "Epoch [20], Train Loss: 0.000134, Val Loss: 0.000106\n",
            "Epoch [21], Train Loss: 0.000133, Val Loss: 0.000112\n",
            "Epoch [22], Train Loss: 0.000129, Val Loss: 0.000112\n",
            "Epoch [23], Train Loss: 0.000129, Val Loss: 0.000109\n",
            "Epoch [24], Train Loss: 0.000132, Val Loss: 0.000122\n",
            "Epoch [25], Train Loss: 0.000135, Val Loss: 0.000120\n",
            "Epoch [26], Train Loss: 0.000134, Val Loss: 0.000115\n",
            "Epoch [27], Train Loss: 0.000128, Val Loss: 0.000114\n",
            "Epoch [28], Train Loss: 0.000126, Val Loss: 0.000120\n",
            "Epoch [29], Train Loss: 0.000128, Val Loss: 0.000116\n",
            "Epoch [30], Train Loss: 0.000138, Val Loss: 0.000141\n",
            "Epoch [31], Train Loss: 0.000137, Val Loss: 0.000119\n",
            "Epoch [32], Train Loss: 0.000128, Val Loss: 0.000116\n",
            "Epoch [33], Train Loss: 0.000124, Val Loss: 0.000118\n",
            "Epoch [34], Train Loss: 0.000139, Val Loss: 0.000126\n",
            "Epoch [35], Train Loss: 0.000129, Val Loss: 0.000122\n",
            "Epoch [36], Train Loss: 0.000126, Val Loss: 0.000118\n",
            "Epoch [37], Train Loss: 0.000133, Val Loss: 0.000125\n",
            "Epoch [38], Train Loss: 0.000130, Val Loss: 0.000127\n",
            "Epoch [39], Train Loss: 0.000125, Val Loss: 0.000119\n",
            "Epoch [40], Train Loss: 0.000124, Val Loss: 0.000123\n",
            "Epoch [41], Train Loss: 0.000125, Val Loss: 0.000135\n",
            "Early stopping after 41 epochs.\n",
            "Iteration 8 Metrics: MSE=0.000135, RMSE=0.011607, MAE=0.002801, R2=0.988487, Corr=0.994287\n",
            "s_full [-0.14802063  0.         51.30830765 -3.6352458 ]\n",
            "s_full [ -0.65953708   0.         -50.32622528  30.47820282]\n",
            "s_full [  0.45654067   0.          66.12901306 -20.57317924]\n",
            "s_full [  0.79265541   0.          59.13415146 -21.77820015]\n",
            "s_full [  0.43154982   0.          81.15003967 -22.34746361]\n",
            "s_full [  0.06730987   0.         -64.77487183   6.79125023]\n",
            "s_full [  1.49935222   0.          51.183815   -25.16849518]\n",
            "s_full [  0.14072528   0.         -55.43384933   0.40139595]\n",
            "s_full [ -0.1578968    0.         -92.51813507  26.12820244]\n",
            "s_full [  0.16012472   0.         -72.63270569   6.67991257]\n",
            "feasible states 0\n",
            "\n",
            "=== DAgger Iteration 9 ===\n",
            "Epoch [1], Train Loss: 0.000113, Val Loss: 0.000176\n",
            "Epoch [2], Train Loss: 0.000114, Val Loss: 0.000178\n",
            "Epoch [3], Train Loss: 0.000116, Val Loss: 0.000178\n",
            "Epoch [4], Train Loss: 0.000112, Val Loss: 0.000184\n",
            "Epoch [5], Train Loss: 0.000109, Val Loss: 0.000183\n",
            "Epoch [6], Train Loss: 0.000110, Val Loss: 0.000192\n",
            "Epoch [7], Train Loss: 0.000111, Val Loss: 0.000181\n",
            "Epoch [8], Train Loss: 0.000113, Val Loss: 0.000179\n",
            "Epoch [9], Train Loss: 0.000114, Val Loss: 0.000199\n",
            "Epoch [10], Train Loss: 0.000108, Val Loss: 0.000181\n",
            "Epoch [11], Train Loss: 0.000111, Val Loss: 0.000181\n",
            "Epoch [12], Train Loss: 0.000106, Val Loss: 0.000186\n",
            "Epoch [13], Train Loss: 0.000122, Val Loss: 0.000182\n",
            "Epoch [14], Train Loss: 0.000110, Val Loss: 0.000179\n",
            "Epoch [15], Train Loss: 0.000106, Val Loss: 0.000186\n",
            "Epoch [16], Train Loss: 0.000108, Val Loss: 0.000183\n",
            "Epoch [17], Train Loss: 0.000106, Val Loss: 0.000188\n",
            "Epoch [18], Train Loss: 0.000123, Val Loss: 0.000187\n",
            "Epoch [19], Train Loss: 0.000107, Val Loss: 0.000186\n",
            "Epoch [20], Train Loss: 0.000109, Val Loss: 0.000184\n",
            "Epoch [21], Train Loss: 0.000106, Val Loss: 0.000183\n",
            "Epoch [22], Train Loss: 0.000106, Val Loss: 0.000192\n",
            "Epoch [23], Train Loss: 0.000108, Val Loss: 0.000195\n",
            "Epoch [24], Train Loss: 0.000118, Val Loss: 0.000190\n",
            "Epoch [25], Train Loss: 0.000105, Val Loss: 0.000190\n",
            "Epoch [26], Train Loss: 0.000115, Val Loss: 0.000183\n",
            "Epoch [27], Train Loss: 0.000106, Val Loss: 0.000187\n",
            "Epoch [28], Train Loss: 0.000106, Val Loss: 0.000187\n",
            "Epoch [29], Train Loss: 0.000106, Val Loss: 0.000191\n",
            "Epoch [30], Train Loss: 0.000109, Val Loss: 0.000188\n",
            "Epoch [31], Train Loss: 0.000107, Val Loss: 0.000196\n",
            "Epoch [32], Train Loss: 0.000107, Val Loss: 0.000190\n",
            "Epoch [33], Train Loss: 0.000104, Val Loss: 0.000187\n",
            "Epoch [34], Train Loss: 0.000106, Val Loss: 0.000198\n",
            "Epoch [35], Train Loss: 0.000106, Val Loss: 0.000187\n",
            "Epoch [36], Train Loss: 0.000106, Val Loss: 0.000187\n",
            "Epoch [37], Train Loss: 0.000114, Val Loss: 0.000192\n",
            "Epoch [38], Train Loss: 0.000106, Val Loss: 0.000187\n",
            "Epoch [39], Train Loss: 0.000111, Val Loss: 0.000199\n",
            "Epoch [40], Train Loss: 0.000106, Val Loss: 0.000192\n",
            "Epoch [41], Train Loss: 0.000117, Val Loss: 0.000195\n",
            "Early stopping after 41 epochs.\n",
            "Iteration 9 Metrics: MSE=0.000195, RMSE=0.013961, MAE=0.003027, R2=0.984576, Corr=0.992391\n",
            "s_full [-0.25148448  0.         69.87504578 -3.18576717]\n",
            "s_full [  0.44978824   0.          62.55820465 -29.63057137]\n",
            "s_full [  0.16122702   0.         -52.03406906  -0.88755465]\n",
            "s_full [ -1.27404439   0.         -86.49277496  23.95488167]\n",
            "s_full [ -0.32137835   0.         -51.75082397  19.71210098]\n",
            "s_full [  0.61525702   0.         -80.6571579   20.28418541]\n",
            "s_full [  0.64954376   0.          61.36042404 -29.53812027]\n",
            "s_full [ 1.85053721e-02  0.00000000e+00 -7.94407196e+01  1.52480888e+01]\n",
            "s_full [  0.81365108   0.          56.47299576 -21.60172272]\n",
            "s_full [-0.18974921  0.         52.67763138 -1.83611143]\n",
            "feasible states 0\n",
            "\n",
            "=== DAgger Iteration 10 ===\n",
            "Epoch [1], Train Loss: 0.000112, Val Loss: 0.000154\n",
            "Epoch [2], Train Loss: 0.000109, Val Loss: 0.000178\n",
            "Epoch [3], Train Loss: 0.000116, Val Loss: 0.000166\n",
            "Epoch [4], Train Loss: 0.000107, Val Loss: 0.000185\n",
            "Epoch [5], Train Loss: 0.000110, Val Loss: 0.000174\n",
            "Epoch [6], Train Loss: 0.000104, Val Loss: 0.000184\n",
            "Epoch [7], Train Loss: 0.000108, Val Loss: 0.000192\n",
            "Epoch [8], Train Loss: 0.000107, Val Loss: 0.000192\n",
            "Epoch [9], Train Loss: 0.000103, Val Loss: 0.000195\n",
            "Epoch [10], Train Loss: 0.000103, Val Loss: 0.000205\n",
            "Epoch [11], Train Loss: 0.000102, Val Loss: 0.000209\n",
            "Epoch [12], Train Loss: 0.000104, Val Loss: 0.000207\n",
            "Epoch [13], Train Loss: 0.000107, Val Loss: 0.000200\n",
            "Epoch [14], Train Loss: 0.000100, Val Loss: 0.000195\n",
            "Epoch [15], Train Loss: 0.000102, Val Loss: 0.000209\n",
            "Epoch [16], Train Loss: 0.000102, Val Loss: 0.000202\n",
            "Epoch [17], Train Loss: 0.000099, Val Loss: 0.000210\n",
            "Epoch [18], Train Loss: 0.000102, Val Loss: 0.000207\n",
            "Epoch [19], Train Loss: 0.000102, Val Loss: 0.000206\n",
            "Epoch [20], Train Loss: 0.000103, Val Loss: 0.000209\n",
            "Epoch [21], Train Loss: 0.000100, Val Loss: 0.000207\n",
            "Epoch [22], Train Loss: 0.000101, Val Loss: 0.000218\n",
            "Epoch [23], Train Loss: 0.000099, Val Loss: 0.000229\n",
            "Epoch [24], Train Loss: 0.000101, Val Loss: 0.000218\n",
            "Epoch [25], Train Loss: 0.000101, Val Loss: 0.000222\n",
            "Epoch [26], Train Loss: 0.000097, Val Loss: 0.000219\n",
            "Epoch [27], Train Loss: 0.000095, Val Loss: 0.000237\n",
            "Epoch [28], Train Loss: 0.000103, Val Loss: 0.000221\n",
            "Epoch [29], Train Loss: 0.000096, Val Loss: 0.000221\n",
            "Epoch [30], Train Loss: 0.000098, Val Loss: 0.000222\n",
            "Epoch [31], Train Loss: 0.000097, Val Loss: 0.000221\n",
            "Epoch [32], Train Loss: 0.000097, Val Loss: 0.000224\n",
            "Epoch [33], Train Loss: 0.000094, Val Loss: 0.000223\n",
            "Epoch [34], Train Loss: 0.000094, Val Loss: 0.000249\n",
            "Epoch [35], Train Loss: 0.000096, Val Loss: 0.000227\n",
            "Epoch [36], Train Loss: 0.000097, Val Loss: 0.000239\n",
            "Epoch [37], Train Loss: 0.000099, Val Loss: 0.000242\n",
            "Epoch [38], Train Loss: 0.000096, Val Loss: 0.000230\n",
            "Epoch [39], Train Loss: 0.000099, Val Loss: 0.000239\n",
            "Epoch [40], Train Loss: 0.000093, Val Loss: 0.000226\n",
            "Epoch [41], Train Loss: 0.000093, Val Loss: 0.000225\n",
            "Early stopping after 41 epochs.\n",
            "Iteration 10 Metrics: MSE=0.000225, RMSE=0.015000, MAE=0.003078, R2=0.982786, Corr=0.991414\n",
            "s_full [ -0.58136296   0.         -86.62335968  26.4750824 ]\n",
            "s_full [  0.85828018   0.          61.52259827 -24.22403336]\n",
            "s_full [-0.1770436   0.         51.6991272   1.39224327]\n",
            "s_full [ -0.3191452    0.         -57.58832932  22.1729393 ]\n",
            "s_full [  0.11091383   0.         -74.15497589   8.42777252]\n",
            "s_full [  0.87904578   0.          78.64798737 -26.69163704]\n",
            "s_full [  0.95551848   0.          50.41904068 -23.61267281]\n",
            "s_full [ -1.35639119   0.         -99.2953949   27.82641792]\n",
            "feasible states 100\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAgger-trained model saved: nmpc_nn_dagger.pth\n",
            "DAgger-trained model converted to NumPy file: nmpc_nn_dagger.npz\n",
            "Iteration |        MSE |       RMSE |        MAE |         R2 |       Corr\n",
            "----------------------------------------------------------------------\n",
            "        1 | 0.000003 | 0.001685 | 0.000810 | 0.999778 | 0.999889\n",
            "        2 | 0.000220 | 0.014831 | 0.004242 | 0.982670 | 0.991786\n",
            "        3 | 0.000175 | 0.013210 | 0.002570 | 0.986860 | 0.993431\n",
            "        4 | 0.000040 | 0.006335 | 0.002324 | 0.996737 | 0.998388\n",
            "        5 | 0.000144 | 0.011993 | 0.004631 | 0.988917 | 0.994852\n",
            "        6 | 0.000132 | 0.011483 | 0.002500 | 0.988774 | 0.994373\n",
            "        7 | 0.000065 | 0.008045 | 0.003083 | 0.993594 | 0.997068\n",
            "        8 | 0.000135 | 0.011607 | 0.002801 | 0.988487 | 0.994287\n",
            "        9 | 0.000195 | 0.013961 | 0.003027 | 0.984576 | 0.992391\n",
            "       10 | 0.000225 | 0.015000 | 0.003078 | 0.982786 | 0.991414\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -------------------- Run DAgger --------------------\n",
        "# model = NMPCNet()\n",
        "dagger_model = dagger_training(model, initial_loader)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(all_train_losses, label='Train Loss')\n",
        "plt.plot(all_val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs across all iterations')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.title('DAgger Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# -------------------- Save Final Model --------------------\n",
        "torch.save(dagger_model.state_dict(), 'nmpc_nn_dagger.pth')\n",
        "print(\"DAgger-trained model saved: nmpc_nn_dagger.pth\")\n",
        "\n",
        "weights = {name: param.detach().numpy() for name, param in dagger_model.named_parameters()}\n",
        "weights['mean'] = mean\n",
        "weights['std'] = std\n",
        "np.savez(\"nmpc_nn_dagger.npz\", **weights)\n",
        "print(\"DAgger-trained model converted to NumPy file: nmpc_nn_dagger.npz\")\n",
        "\n",
        "print(f\"{'Iteration':>9} | {'MSE':>10} | {'RMSE':>10} | {'MAE':>10} | {'R2':>10} | {'Corr':>10}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Print each iteration's metrics\n",
        "for m in dagger_iteration_metrics:\n",
        "    print(f\"{m['iteration']:>9} | \"\n",
        "          f\"{m['MSE']:.6f} | \"\n",
        "          f\"{m['RMSE']:.6f} | \"\n",
        "          f\"{m['MAE']:.6f} | \"\n",
        "          f\"{m['R2']:.6f} | \"\n",
        "          f\"{m['Correlation']:.6f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR/r9SL+BkIXayRS7p8RC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}